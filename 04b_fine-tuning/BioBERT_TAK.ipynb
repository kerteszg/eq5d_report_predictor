{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DpLDSRFjEUE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random as rand\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, TFBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0YnybPriUKg"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer):\n",
    "        # Load BERT tokenizer\n",
    "        # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Load BERT model\n",
    "        model = TFBertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-v1.1\", from_pt=True)\n",
    "\n",
    "        # Set up optimizer and loss function\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # transfer learning vs re-training pre-trained BERT model on smaller lr\n",
    "        model.layers[0].trainable = Trainable\n",
    "        print (\"Learning rate: \" + str(lr) + \"    Trainable: \" + str(Trainable))\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])\n",
    "        es = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "        hist = model.fit(train_dataset, epochs=1000, \n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "        \n",
    "        #plt.plot(hist.history[\"loss\"])\n",
    "        #plt.plot(hist.history[\"val_loss\"])\n",
    "        vissza = [len(hist.history[\"loss\"]), model.evaluate(train_dataset, verbose=0), model.evaluate(val_dataset, verbose=0), model.evaluate(test_dataset, verbose=0)]\n",
    "        return vissza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'title_abstract_keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/train_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing measurement properties of EQ-5D-Y-3L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Feasibility of the EQ-5D in the elderly popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing the self-reported health-related qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Testing measurement properties of two EQ-5D yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Use of Antimalarial Agents is Associated with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Comparing measurement properties of EQ-5D-Y-3L...\n",
       "1      0  Feasibility of the EQ-5D in the elderly popula...\n",
       "2      1  Comparing the self-reported health-related qua...\n",
       "3      1  Testing measurement properties of two EQ-5D yo...\n",
       "4      1  Use of Antimalarial Agents is Associated with ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random stratified validation subset split\n",
    "#_diff = 1\n",
    "#while _diff >= .02:\n",
    "#    tts = train_dataset.train_test_split(test_size=.15, shuffle=True)\n",
    "#    _train_ratio, _val_ratio = np.sum(tts[\"train\"][\"label\"]) / len(tts[\"train\"][\"label\"]), np.sum(tts[\"test\"][\"label\"]) / len(tts[\"test\"][\"label\"])\n",
    "#    _diff = abs(_train_ratio - _val_ratio)\n",
    "#    print(_train_ratio, _val_ratio, _diff)\n",
    "#\n",
    "#train_dataset = tts[\"train\"]\n",
    "#val_dataset = tts[\"test\"]\n",
    "\n",
    "\n",
    "#subsets should be fixed for all tests\n",
    "_val_ids = [2, 7, 24, 32, 36, 47, 49, 59, 61, 71, 72, 86, 90, 95, 96]\n",
    "train_dataset = Dataset.from_pandas(df[~df.index.isin(_val_ids)])\n",
    "val_dataset = Dataset.from_pandas(df[df.index.isin(_val_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.611764705882353, 0.6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_dataset[\"label\"]) / len(train_dataset[\"label\"]), np.sum(val_dataset[\"label\"]) / len(val_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/test_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_dataset[\"label\"]) / len(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1ICeIiykZv"
   },
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "4136d11d23304f44a6fd77bd5078c678",
      "858f4eafdb214acd80236294e009f285",
      "a38b3162339e4d49a7c705818d3d9014",
      "b7a8f10c56f84fce8fd9e0325b3c444e",
      "0e5baf42d613466c9789d6ed74223515",
      "cbfb95452bce4570805ef71e5fce0121",
      "a3cddd07fc284418982f9bd6cba0e89f",
      "d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "49684e0c97d34a558c268306fbbdf3f4",
      "ac8ce475408a49669d263c85042f9530",
      "b033809b6f434f12b338b3ac2119da37",
      "09d3283c59714ec4bb76e3d474e14cac",
      "f6a48091bc4f4680acdd64f2a3fee5cc",
      "dcc947b1fa38423b8e579c10f4cad8c3",
      "f5f9b726114849978ff0f8ece12bcba9",
      "928ab0b08c8b4870ac945c5252dbf2ff"
     ]
    },
    "id": "CeS4fX3Jh_tM",
    "outputId": "4a21030d-3d27-4d63-8c06-ba1c10a85dda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def preprocess_function(examples):\n",
    "#    return tokenizer(examples[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encodings = dataset.map(preprocess_function, batched=True)\n",
    "train_encodings = tokenizer(train_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_dataset[\"text\"], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings[0]), len(train_encodings[1]), len(train_encodings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.8375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.sum([t == '[PAD]' for t in train_encodings[e].tokens]) for e in range(0,80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_dataset[\"label\"]\n",
    "val_labels = val_dataset[\"label\"]\n",
    "test_labels = test_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 100s 11s/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6690 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6403 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6357 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6450 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6227 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6406 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6182 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6414 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6161 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6274 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6145 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6336 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6355 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6268 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6076 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6050 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6043 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6038 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5989 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6093 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5969 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5889 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5965 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5836 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5902 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5758 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5827 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5815 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5682 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5665 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5741 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5582 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5731 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5527 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5708 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5324 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5715 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5283 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5714 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5337 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5156 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5248 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5545 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5011 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4833 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4781 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5498 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4773 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4626 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5477 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4386 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5395 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4299 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4342 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5220 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4202 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5170 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4102 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5168 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3974 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5034 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3968 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5006 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3872 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3848 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4857 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3566 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3397 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4940 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3402 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4770 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3301 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3079 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2973 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4540 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2889 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4563 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2763 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2813 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2655 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2604 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4448 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2541 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4469 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2443 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2486 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4501 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2318 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4480 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2258 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4377 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2193 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2100 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2096 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1940 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1919 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1946 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1904 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4378 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1836 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1714 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4428 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1630 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1673 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4631 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [81, [0.19330362975597382, 1.0], [0.4374726414680481, 0.8666666746139526], [0.6579305529594421, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6529 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6790 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6500 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6686 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6666 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6438 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6369 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6530 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6423 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6361 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6239 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6170 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6162 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6158 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6127 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6117 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6145 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6081 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6058 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5950 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6008 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5865 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5936 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5645 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5950 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5882 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5845 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5376 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5260 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5276 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4989 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4975 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5017 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5508 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4858 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4761 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5443 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4699 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5394 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4680 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5435 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4516 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5353 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4504 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4307 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5512 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4195 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4265 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5194 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4062 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5069 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4058 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5098 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3938 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3936 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3847 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5113 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3611 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3714 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4977 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3583 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4961 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3652 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5005 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3541 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4946 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3452 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4842 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3367 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4809 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3292 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3328 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3235 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4933 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3199 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3176 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4858 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3033 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4804 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2936 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4899 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2990 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2778 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4943 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2795 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4932 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2834 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2678 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2658 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2525 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4594 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2563 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4506 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2475 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2364 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4783 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4618 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2271 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2340 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4452 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2127 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4465 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4480 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2043 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4511 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2103 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4606 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2024 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4579 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1933 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4586 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-06 [84, [0.20057357847690582, 0.9882352948188782], [0.4451919496059418, 0.8666666746139526], [0.6781145334243774, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 91s 11s/step - loss: 0.7223 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7262 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7191 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7075 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6995 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6794 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6744 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6474 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6395 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6331 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6197 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6305 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6350 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6182 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6303 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6094 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6082 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6033 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6214 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5990 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6172 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5861 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6135 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6003 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5850 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6077 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5591 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5981 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5624 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5592 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5396 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5902 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5480 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5390 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5812 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5277 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5262 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5700 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5190 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5663 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5169 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4929 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5631 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4967 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5595 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4935 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5521 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4838 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5468 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4789 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5452 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4705 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4556 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4508 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5395 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4623 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4471 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4407 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5304 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4369 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5363 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4050 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5300 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5232 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5208 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4014 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3890 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5223 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3929 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5171 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3837 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5142 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3785 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5081 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3747 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5063 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5108 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3687 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5149 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3641 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5104 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3543 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5035 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3529 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5040 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3483 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5066 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3528 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4987 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3337 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3339 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3216 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4937 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3344 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4910 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3248 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4894 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3288 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3051 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3031 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4838 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3116 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4863 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3018 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2863 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4813 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2942 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4788 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2891 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4858 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2862 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2873 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4803 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2754 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2697 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2612 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4698 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2709 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2590 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4684 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2577 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2512 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2459 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2433 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2336 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4630 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2295 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2218 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4657 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2120 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4636 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2114 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2069 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1925 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4697 - val_sparse_categorical_accuracy: 0.7333\n",
      "1e-06 [106, [0.20840492844581604, 0.9764705896377563], [0.462622731924057, 0.7333333492279053], [0.7005138993263245, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.7604 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7434 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7443 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.7180 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7334 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7080 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7213 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7059 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7025 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6780 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6472 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6413 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6295 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6239 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6421 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6193 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6130 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6145 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6154 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6091 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6162 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6051 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5978 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5988 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5925 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5918 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5948 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5837 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5875 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5794 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5855 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5707 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5710 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5612 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5668 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5666 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5632 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5611 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5456 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5544 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5500 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5248 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5268 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5413 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5185 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5371 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5142 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5330 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5013 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4990 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5249 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4963 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5208 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4869 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5168 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4774 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5128 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4561 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5086 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4648 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5047 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4487 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5013 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4356 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4985 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4946 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4238 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4125 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4874 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4120 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4119 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4800 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3933 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3925 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4735 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3970 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3818 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3642 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3627 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3600 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4591 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3521 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3387 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4546 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3439 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4516 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3349 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4487 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3287 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3170 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4454 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3273 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4436 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3044 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3098 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3065 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2929 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2926 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2858 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2784 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2785 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2736 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4281 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2681 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4265 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2514 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4252 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2479 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4246 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2524 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2425 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4177 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2380 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2362 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4161 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2351 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4162 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2251 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4160 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2167 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2188 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4109 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2210 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4105 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4105 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2067 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4114 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2039 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4115 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2003 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4113 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1969 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4109 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1910 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4100 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1826 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1871 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4065 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1775 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4086 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1749 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4102 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1700 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1667 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4156 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4161 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1615 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4170 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1548 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4156 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1565 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4158 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1538 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1504 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4213 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-06 [102, [0.15849950909614563, 1.0], [0.40647849440574646, 0.8666666746139526], [0.7228655815124512, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6367 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6373 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6364 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6412 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6221 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6189 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6194 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6099 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6601 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6090 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6113 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6015 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6004 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5968 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6396 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5765 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6371 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5684 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5689 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5569 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6277 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5517 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5514 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6180 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5433 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6141 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5388 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6082 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5339 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6033 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5294 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5267 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5981 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5227 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5192 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5066 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5893 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5213 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5854 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4999 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4993 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5739 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4966 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4779 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5722 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4739 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4720 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4653 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5654 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4414 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4269 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5621 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4207 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5608 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4256 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4258 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5539 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.3926 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3954 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5494 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3901 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3854 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5442 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3736 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3803 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5437 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3593 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3644 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5429 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3522 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3535 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5399 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3420 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5332 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3348 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5345 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3323 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3351 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3169 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3231 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5318 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3212 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5255 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3072 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5257 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3070 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5259 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2994 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5267 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3020 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5266 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2951 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5258 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2859 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5240 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2882 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5243 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2793 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5262 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2675 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2761 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5294 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2739 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2633 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5281 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2551 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2484 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5275 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5258 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2422 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5223 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2417 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5207 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2389 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5206 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2327 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5218 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2285 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5227 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2294 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2210 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5182 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5222 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2111 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5231 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2131 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5238 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2044 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5208 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2006 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5153 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1990 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5176 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1961 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5202 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1904 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5211 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1872 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1848 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5279 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1761 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5306 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5321 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1673 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1676 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5320 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [107, [0.18188871443271637, 1.0], [0.5152978897094727, 0.800000011920929], [0.7465880513191223, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 95s 11s/step - loss: 0.7681 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6987 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6435 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6308 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6006 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5961 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5866 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5806 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5477 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5320 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5251 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5243 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5098 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5144 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4966 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5058 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4633 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4979 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4732 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4511 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4828 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4265 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4767 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4029 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3747 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4678 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3469 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3567 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3143 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3229 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2865 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4571 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2659 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2707 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2544 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2327 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2358 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4531 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2268 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4527 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2141 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4506 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1947 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4486 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1976 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4467 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1894 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1877 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4460 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1747 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4465 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1787 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1669 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1732 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4506 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1593 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1498 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4532 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1504 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4527 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1456 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1420 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [43, [0.17654180526733398, 1.0], [0.4456600844860077, 0.8666666746139526], [0.7585409283638, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 93s 11s/step - loss: 0.7024 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6568 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6552 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6498 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6384 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6346 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6168 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6179 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6123 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5988 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5877 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5849 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5837 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5685 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5568 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5560 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5572 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5227 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5467 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5145 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5076 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5662 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4843 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5487 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4590 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5279 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4466 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5073 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4396 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5117 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4104 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5258 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3980 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5185 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3987 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3741 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4696 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3593 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5068 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3583 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5267 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3347 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3414 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4421 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3193 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2969 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4864 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2912 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2821 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4323 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2818 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4349 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2655 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2376 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2308 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2084 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1850 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1785 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1634 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4245 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1602 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4300 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1499 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4487 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1357 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1344 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1332 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1202 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4231 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1173 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1089 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1037 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1009 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0953 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4340 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0895 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0934 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0871 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0823 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [60, [0.1072307676076889, 1.0], [0.42033568024635315, 0.8666666746139526], [0.7103212475776672, 0.6899999976158142]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6974 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6605 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6477 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6268 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6121 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5999 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6152 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6075 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5726 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5622 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5171 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5459 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5166 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5368 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5018 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4830 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5225 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4650 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5152 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4549 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5107 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4415 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5068 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4202 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5029 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4082 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.4983 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3978 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4949 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3894 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4900 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3614 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4847 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3572 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4877 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3453 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4899 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3349 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4839 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3222 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4855 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3149 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4934 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3124 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2830 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4927 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2750 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5025 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2691 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5042 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2594 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5035 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2490 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4900 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2314 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4871 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4975 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [39, [0.3063243627548218, 0.929411768913269], [0.48392659425735474, 0.800000011920929], [0.6775648593902588, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.7164 - sparse_categorical_accuracy: 0.3412 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6906 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6783 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6452 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6305 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6243 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6187 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6215 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6008 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5957 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5758 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5626 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5508 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5490 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5265 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5325 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5107 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5166 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4973 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5169 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4723 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4540 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5086 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4935 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3803 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3731 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4910 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3651 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3724 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4828 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3476 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4848 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3330 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4670 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3262 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3057 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4750 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2994 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2792 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2824 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2862 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4609 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2678 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2502 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2362 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2286 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4678 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2029 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4617 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4601 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [45, [0.24621324241161346, 0.9882352948188782], [0.45341795682907104, 0.800000011920929], [0.7197187542915344, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_379 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6389 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6518 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6179 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6218 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6115 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6124 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6056 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5839 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5679 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5906 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5655 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5601 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5305 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5588 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5234 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5487 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5023 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5403 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4991 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5308 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4716 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5233 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4646 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5186 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4487 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5071 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4381 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4995 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4278 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4153 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4913 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4014 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4772 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3735 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3660 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4754 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3583 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3402 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3244 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4566 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3292 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4584 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3154 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4566 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3003 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4486 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2939 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4445 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2755 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2705 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4371 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2551 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4314 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2431 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2339 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4206 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4162 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4103 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1927 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4134 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4001 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1827 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3940 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1712 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3931 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1665 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3856 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.1484 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3827 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3867 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3867 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3824 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3770 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3745 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3716 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3760 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3768 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3727 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0772 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0684 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3702 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3706 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0638 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3706 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0649 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3718 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0606 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3736 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0491 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3732 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0499 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0472 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [79, [0.058466535061597824, 1.0], [0.37024837732315063, 0.8666666746139526], [0.8977489471435547, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_417 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6194 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5856 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5665 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5254 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5664 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4988 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4783 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4368 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5203 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3962 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5066 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3692 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4912 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4699 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3247 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2817 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4794 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2608 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2515 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4636 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2319 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2207 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4479 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1995 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1903 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1776 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1621 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4436 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1515 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1361 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1289 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1257 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1170 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4810 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1045 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0939 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4789 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0871 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4813 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0797 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0760 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4908 - val_sparse_categorical_accuracy: 0.8667\n",
      "5e-06 [31, [0.14460279047489166, 1.0], [0.4435735046863556, 0.8666666746139526], [0.7559387683868408, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6449 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5938 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5897 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5746 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6021 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5461 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5289 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5885 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5590 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4699 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5659 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4525 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4027 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5388 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3956 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5227 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3653 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5293 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3129 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2907 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5041 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2723 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5193 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5239 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2339 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2199 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5132 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1891 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5158 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1790 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5246 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1615 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5254 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1478 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5366 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1327 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1174 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-06 [27, [0.29567813873291016, 0.9647058844566345], [0.5040996670722961, 0.7333333492279053], [0.708428144454956, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_493 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6227 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6317 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6318 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5871 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5978 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5920 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5679 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5332 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5178 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5248 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4721 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4970 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4535 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4980 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4041 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3474 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3273 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2947 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4236 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2677 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2438 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4048 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4044 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1893 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4044 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1693 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1431 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3980 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1256 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1083 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4069 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1001 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4128 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0869 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.0740 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0698 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0619 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0594 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0504 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5413 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [28, [0.130890890955925, 1.0], [0.3950067460536957, 0.8666666746139526], [0.6769981980323792, 0.6899999976158142]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_531 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 92s 11s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6403 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6128 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6005 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5782 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5524 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5315 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4989 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5173 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4738 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4999 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 63s 11s/step - loss: 0.4510 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3959 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3595 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4615 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3191 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4687 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2907 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.2674 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2433 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2204 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1723 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1652 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1429 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4452 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1379 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1230 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1203 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4377 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1047 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0962 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0889 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0865 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0723 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4524 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0653 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0609 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0568 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4834 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0514 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4891 - val_sparse_categorical_accuracy: 0.8667\n",
      "5e-06 [32, [0.10377369821071625, 1.0], [0.43312549591064453, 0.800000011920929], [0.7540760040283203, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_569 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 93s 11s/step - loss: 0.6847 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6164 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6054 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5706 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6227 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.5474 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5093 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5916 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4635 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4177 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3957 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3658 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5506 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3373 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2947 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2656 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5428 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1872 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5855 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5784 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.6121 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-06 [23, [0.3046311140060425, 0.9647058844566345], [0.5288025140762329, 0.7333333492279053], [0.7186647057533264, 0.6299999952316284]]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load BERT model\n",
    "Trainable = True\n",
    "for lr in [1e-4, 2e-4, 5e-4, 1e-5, 2e-5, 5e-5, 1e-6, 2e-6, 5e-6]:\n",
    "    for Ismetles in range (0,5):\n",
    "        TestEredmeny = func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer)\n",
    "        print(lr,  TestEredmeny)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextClassificationDS2A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09d3283c59714ec4bb76e3d474e14cac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928ab0b08c8b4870ac945c5252dbf2ff",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f9b726114849978ff0f8ece12bcba9",
      "value": " 228k/228k [00:02&lt;00:00, 76.8kB/s]"
     }
    },
    "0e5baf42d613466c9789d6ed74223515": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24a91bb3dd86425ebe0dd489d07a99e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "382bcdaba94748dfba4de9ac6df3d0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4136d11d23304f44a6fd77bd5078c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a38b3162339e4d49a7c705818d3d9014",
       "IPY_MODEL_b7a8f10c56f84fce8fd9e0325b3c444e"
      ],
      "layout": "IPY_MODEL_858f4eafdb214acd80236294e009f285"
     }
    },
    "49684e0c97d34a558c268306fbbdf3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b033809b6f434f12b338b3ac2119da37",
       "IPY_MODEL_09d3283c59714ec4bb76e3d474e14cac"
      ],
      "layout": "IPY_MODEL_ac8ce475408a49669d263c85042f9530"
     }
    },
    "59e835dce3754a3da47bd3d3106843a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10fdb6c1963442d8dc23bfa989e8183",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b11ffa580c40481890990666b9813e33",
      "value": 442221694
     }
    },
    "858f4eafdb214acd80236294e009f285": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "928ab0b08c8b4870ac945c5252dbf2ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dd6e58d01ff4bcba634f49e52de97b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59e835dce3754a3da47bd3d3106843a8",
       "IPY_MODEL_b1c95a342bd149aa9940cb4b6290f6cc"
      ],
      "layout": "IPY_MODEL_9e1afcdfeaf4406e860f74b6d4fa5634"
     }
    },
    "9e1afcdfeaf4406e860f74b6d4fa5634": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a38b3162339e4d49a7c705818d3d9014": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfb95452bce4570805ef71e5fce0121",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e5baf42d613466c9789d6ed74223515",
      "value": 385
     }
    },
    "a3cddd07fc284418982f9bd6cba0e89f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac8ce475408a49669d263c85042f9530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b033809b6f434f12b338b3ac2119da37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc947b1fa38423b8e579c10f4cad8c3",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6a48091bc4f4680acdd64f2a3fee5cc",
      "value": 227845
     }
    },
    "b11ffa580c40481890990666b9813e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1c95a342bd149aa9940cb4b6290f6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24a91bb3dd86425ebe0dd489d07a99e6",
      "placeholder": "​",
      "style": "IPY_MODEL_382bcdaba94748dfba4de9ac6df3d0fc",
      "value": " 442M/442M [00:12&lt;00:00, 34.2MB/s]"
     }
    },
    "b7a8f10c56f84fce8fd9e0325b3c444e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "placeholder": "​",
      "style": "IPY_MODEL_a3cddd07fc284418982f9bd6cba0e89f",
      "value": " 385/385 [00:01&lt;00:00, 323B/s]"
     }
    },
    "c10fdb6c1963442d8dc23bfa989e8183": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfb95452bce4570805ef71e5fce0121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1fd9a54bdb847a3a4ac6a9e49f8bea6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc947b1fa38423b8e579c10f4cad8c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f9b726114849978ff0f8ece12bcba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6a48091bc4f4680acdd64f2a3fee5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
