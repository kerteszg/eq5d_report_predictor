{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DpLDSRFjEUE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random as rand\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, TFBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0YnybPriUKg"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer):\n",
    "        # Load BERT tokenizer\n",
    "        # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Load BERT model\n",
    "        model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', from_pt=True)\n",
    "\n",
    "        # Set up optimizer and loss function\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # transfer learning vs re-training pre-trained BERT model on smaller lr\n",
    "        model.layers[0].trainable = Trainable\n",
    "        print (\"Learning rate: \" + str(lr) + \"    Trainable: \" + str(Trainable))\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])\n",
    "        es = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "        hist = model.fit(train_dataset, epochs=1000, \n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "        \n",
    "        #plt.plot(hist.history[\"loss\"])\n",
    "        #plt.plot(hist.history[\"val_loss\"])\n",
    "        vissza = [len(hist.history[\"loss\"]), model.evaluate(train_dataset, verbose=0), model.evaluate(val_dataset, verbose=0), model.evaluate(test_dataset, verbose=0)]\n",
    "        return vissza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'title_abstract_keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/train_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing measurement properties of EQ-5D-Y-3L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Feasibility of the EQ-5D in the elderly popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing the self-reported health-related qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Testing measurement properties of two EQ-5D yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Use of Antimalarial Agents is Associated with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Comparing measurement properties of EQ-5D-Y-3L...\n",
       "1      0  Feasibility of the EQ-5D in the elderly popula...\n",
       "2      1  Comparing the self-reported health-related qua...\n",
       "3      1  Testing measurement properties of two EQ-5D yo...\n",
       "4      1  Use of Antimalarial Agents is Associated with ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random stratified validation subset split\n",
    "#_diff = 1\n",
    "#while _diff >= .02:\n",
    "#    tts = train_dataset.train_test_split(test_size=.15, shuffle=True)\n",
    "#    _train_ratio, _val_ratio = np.sum(tts[\"train\"][\"label\"]) / len(tts[\"train\"][\"label\"]), np.sum(tts[\"test\"][\"label\"]) / len(tts[\"test\"][\"label\"])\n",
    "#    _diff = abs(_train_ratio - _val_ratio)\n",
    "#    print(_train_ratio, _val_ratio, _diff)\n",
    "#\n",
    "#train_dataset = tts[\"train\"]\n",
    "#val_dataset = tts[\"test\"]\n",
    "\n",
    "\n",
    "#subsets should be fixed for all tests\n",
    "_val_ids = [2, 7, 24, 32, 36, 47, 49, 59, 61, 71, 72, 86, 90, 95, 96]\n",
    "train_dataset = Dataset.from_pandas(df[~df.index.isin(_val_ids)])\n",
    "val_dataset = Dataset.from_pandas(df[df.index.isin(_val_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.611764705882353, 0.6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_dataset[\"label\"]) / len(train_dataset[\"label\"]), np.sum(val_dataset[\"label\"]) / len(val_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/test_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_dataset[\"label\"]) / len(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1ICeIiykZv"
   },
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "4136d11d23304f44a6fd77bd5078c678",
      "858f4eafdb214acd80236294e009f285",
      "a38b3162339e4d49a7c705818d3d9014",
      "b7a8f10c56f84fce8fd9e0325b3c444e",
      "0e5baf42d613466c9789d6ed74223515",
      "cbfb95452bce4570805ef71e5fce0121",
      "a3cddd07fc284418982f9bd6cba0e89f",
      "d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "49684e0c97d34a558c268306fbbdf3f4",
      "ac8ce475408a49669d263c85042f9530",
      "b033809b6f434f12b338b3ac2119da37",
      "09d3283c59714ec4bb76e3d474e14cac",
      "f6a48091bc4f4680acdd64f2a3fee5cc",
      "dcc947b1fa38423b8e579c10f4cad8c3",
      "f5f9b726114849978ff0f8ece12bcba9",
      "928ab0b08c8b4870ac945c5252dbf2ff"
     ]
    },
    "id": "CeS4fX3Jh_tM",
    "outputId": "4a21030d-3d27-4d63-8c06-ba1c10a85dda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def preprocess_function(examples):\n",
    "#    return tokenizer(examples[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encodings = dataset.map(preprocess_function, batched=True)\n",
    "train_encodings = tokenizer(train_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_dataset[\"text\"], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings[0]), len(train_encodings[1]), len(train_encodings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.sum([t == '[PAD]' for t in train_encodings[e].tokens]) for e in range(0,80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_dataset[\"label\"]\n",
    "val_labels = val_dataset[\"label\"]\n",
    "test_labels = test_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 99s 11s/step - loss: 0.6941 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6615 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5978 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4757 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5840 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.4886 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4860 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3607 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5043 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2157 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.6184 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.7890 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.9196 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.1741 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.3273 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.2586 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0120 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0160 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9647 - val_loss: 1.0338 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.8000\n",
      "0.0001 [16, [0.3887983560562134, 0.8352941274642944], [0.48602333664894104, 0.800000011920929], [0.7043976783752441, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7790 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6991 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6901 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6839 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6684 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6902 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [14, [0.668509304523468, 0.6117647290229797], [0.6729077696800232, 0.6000000238418579], [0.6730695366859436, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 91s 11s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6026 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5681 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4487 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3871 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0676 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1810 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2334 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.7883 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.8998 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1260 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.8046 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3587 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2552 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0296 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0495 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0244 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0747 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0047 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9336 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9119 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9543 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9917 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0014 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 9.8351e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0061 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 7.9313e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0172 - val_sparse_categorical_accuracy: 0.8667\n",
      "0.0001 [20, [0.11098520457744598, 0.9647058844566345], [0.3932289481163025, 0.8666666746139526], [0.7801129817962646, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.7237 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5900 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7254 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6580 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6153 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5442 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7835 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5320 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4086 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5013 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5389 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.2145 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.7500 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2805 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3146 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9529 - val_loss: 1.0729 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0109 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9760 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 63s 10s/step - loss: 0.0086 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8633 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9398 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0020 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0540 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0870 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1086 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 8.7498e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1248 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 7.8791e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1410 - val_sparse_categorical_accuracy: 0.8000\n",
      "0.0001 [24, [0.04346337541937828, 0.9882352948188782], [0.42768293619155884, 0.800000011920929], [0.9777371287345886, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6983 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6832 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6471 - val_loss: 1.0590 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.8026 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7011 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6460 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6125 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.5803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5313 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.4433 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3557 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6282 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5993 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.4494 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3296 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.8496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2142 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4926 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2678 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.9554 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.9821 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2846 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.9764 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9647 - val_loss: 1.0045 - val_sparse_categorical_accuracy: 0.7333\n",
      "0.0001 [25, [0.3326842188835144, 0.8941176533699036], [0.4433431923389435, 0.8666666746139526], [0.8003582954406738, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7146 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.8242 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7732 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7020 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6832 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6993 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6806 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6771 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6736 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [15, [0.6680124402046204, 0.6117647290229797], [0.6725254058837891, 0.6000000238418579], [0.6728904247283936, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.7832 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7132 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6898 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6926 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6899 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6933 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [12, [0.6686482429504395, 0.6117647290229797], [0.6703627109527588, 0.6000000238418579], [0.6726331114768982, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6937 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7165 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6512 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6365 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5431 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.9359 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7144 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7232 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7260 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.7058 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6807 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6838 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6815 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [18, [0.611142098903656, 0.6117647290229797], [0.636536180973053, 0.6000000238418579], [0.6841033101081848, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7106 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6852 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6736 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6701340079307556, 0.6117647290229797], [0.6694200038909912, 0.6000000238418579], [0.6816368103027344, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_379 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7128 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7422 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7322 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7309 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6993 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6793 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7044 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6828 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6850 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7041 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7143 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6823 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6962 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [16, [0.6682756543159485, 0.6117647290229797], [0.672869086265564, 0.6000000238418579], [0.6729751825332642, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_417 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.8432 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6769 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6838 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [16, [0.6680144667625427, 0.6117647290229797], [0.6730957627296448, 0.6000000238418579], [0.6730954051017761, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7470 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7190 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7007 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7442 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6684 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7076 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6989 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [12, [0.6679720878601074, 0.6117647290229797], [0.6731694936752319, 0.6000000238418579], [0.6731696128845215, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_493 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.8129 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.8075 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7564 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6975 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6787 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7124 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7024 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6787 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6730 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6809 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6592 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6884 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6885 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [24, [0.6683868169784546, 0.6117647290229797], [0.6730263829231262, 0.6000000238418579], [0.673026442527771, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_531 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 85s 10s/step - loss: 0.8422 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6642 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6874 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6853 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6980 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6793 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6906 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6884 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7443 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7028 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6757 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7046 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7079 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6818 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6924 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6827 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6912 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6832 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6800 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7020 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [36, [0.6682862043380737, 0.6117647290229797], [0.67301344871521, 0.6000000238418579], [0.6730133295059204, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_569 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7125 - sparse_categorical_accuracy: 0.6000 - val_loss: 1.2314 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.8559 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7178 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7020 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7042 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7060 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6541 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7026 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [13, [0.6680678129196167, 0.6117647290229797], [0.6730508208274841, 0.6000000238418579], [0.6730509996414185, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_607 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6389 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6231 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5893 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5584 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5881 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5259 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4518 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4471 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3391 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4037 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2599 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4433 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3766 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1896 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1374 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1158 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4205 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0921 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0758 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4017 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0675 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3882 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0590 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4906 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0525 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5134 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0467 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4614 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0409 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0403 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4421 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [21, [0.14473119378089905, 0.9882352948188782], [0.37250009179115295, 0.8666666746139526], [0.7991798520088196, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_645 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6388 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6054 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5812 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5648 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5566 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4946 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4829 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4359 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3638 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3330 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2764 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1919 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3963 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3777 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3709 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1251 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0408 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3525 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0330 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0328 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3408 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0252 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0222 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5329 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0201 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0184 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5675 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0159 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5458 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [25, [0.04253710061311722, 1.0], [0.3406677842140198, 0.9333333373069763], [0.8687219023704529, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_683 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5871 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5758 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5468 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5395 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5044 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5157 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4104 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3779 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3666 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4031 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3212 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.3808 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2605 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4101 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1445 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3694 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0962 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0988 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3791 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0744 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0719 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3763 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0632 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0619 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3827 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0581 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3771 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0553 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0498 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0468 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [23, [0.09149904549121857, 1.0], [0.3693639636039734, 0.9333333373069763], [0.7989096641540527, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_721 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6273 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6121 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6280 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5711 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5398 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5237 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5494 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4791 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4561 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5222 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4197 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4180 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3144 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4870 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3912 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2266 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5208 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1556 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5471 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0939 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0868 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4627 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0757 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4750 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0684 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0548 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4687 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0503 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4161 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0454 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4681 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0372 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4897 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0343 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0294 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4525 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0278 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [25, [0.07685478776693344, 1.0], [0.3480728566646576, 0.9333333373069763], [0.7204608917236328, 0.699999988079071]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_759 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6938 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6426 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6467 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6072 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6028 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5738 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5691 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5137 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5228 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4439 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4192 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.4523 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3659 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4121 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2811 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.3907 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3642 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1259 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3306 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0541 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3281 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0382 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3563 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0313 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0253 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0217 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3468 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0196 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0164 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3695 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0152 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0144 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4088 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0126 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4200 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4265 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [26, [0.030325084924697876, 1.0], [0.3281105160713196, 0.9333333373069763], [0.8117291927337646, 0.6899999976158142]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_797 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6996 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6100 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5053 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4211 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3267 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3754 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1670 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3828 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1016 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3751 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0704 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0505 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0353 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5276 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0256 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5616 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0195 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0159 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8449 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0139 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-05 [16, [0.22834575176239014, 0.9764705896377563], [0.34525802731513977, 0.9333333373069763], [0.6682506799697876, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_835 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6435 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6171 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5722 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5028 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4964 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4269 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3826 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3686 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3047 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3545 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1818 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1303 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3150 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1062 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3253 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0553 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3079 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0455 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3222 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0306 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3205 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0256 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0221 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0200 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0170 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0157 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0146 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0130 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4371 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-05 [21, [0.04177003726363182, 1.0], [0.3079220652580261, 0.9333333373069763], [0.9743317365646362, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_873 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7010 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6552 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6217 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6230 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5577 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5085 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4686 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3551 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4163 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2496 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4085 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0883 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4206 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0517 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0339 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5380 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0194 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3871 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0148 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3542 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0110 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3690 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0094 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3993 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0076 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0065 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0055 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0051 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4533 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0045 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4579 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0041 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4629 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4573 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.9333\n",
      "2e-05 [23, [0.009524461813271046, 1.0], [0.35424768924713135, 0.9333333373069763], [1.2272428274154663, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_911 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7160 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6356 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6026 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5910 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5856 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5009 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5286 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4143 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5374 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3229 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5440 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4697 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1716 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1241 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0865 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4967 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0702 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0502 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8221 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0392 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7890 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0289 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5276 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0243 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5535 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0173 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0145 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-05 [18, [0.15897464752197266, 0.9882352948188782], [0.4697345793247223, 0.800000011920929], [0.8317203521728516, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_949 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6531 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6244 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6152 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5339 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5376 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4441 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3427 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3631 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2801 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5047 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3330 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3601 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0302 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8107 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0290 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7549 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0154 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0115 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5011 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0097 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0076 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0067 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0061 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-05 [18, [0.09725356101989746, 1.0], [0.3329813778400421, 0.9333333373069763], [0.808972954750061, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_987 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6170 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5723 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5291 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5268 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5665 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5366 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4971 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4573 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3734 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3534 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5713 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3931 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.3923 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1927 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.8575 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2277 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0219 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0136 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5615 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0136 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8025 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0459 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5080 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5599 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0037 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1290 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [27, [0.05425750091671944, 0.9882352948188782], [0.3483119308948517, 0.8666666746139526], [0.8993802070617676, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1025 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6975 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6759 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6206 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5296 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5005 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4084 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5914 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2577 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.0432 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.8685 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1345 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.7937 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.9642 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9430 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0086 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0287 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0054 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1440 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2542 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-05 [16, [0.32599717378616333, 0.929411768913269], [0.4763677716255188, 0.800000011920929], [0.6913822889328003, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1063 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.7171 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6848 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5676 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5401 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5048 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3748 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3658 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5636 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2810 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.7873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.7176 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.9855 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.8973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.0889 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [16, [0.44287168979644775, 0.8235294222831726], [0.5337814688682556, 0.800000011920929], [0.7488328814506531, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1101 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6658 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5383 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5348 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4767 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.4217 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3386 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5138 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2487 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3388 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3125 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.8306 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0507 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3234 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.7821 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.8475 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4777 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0154 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0609 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0089 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0703 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0049 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0206 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0114 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3776 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0054 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7519 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [18, [0.06168754771351814, 1.0], [0.3125375211238861, 0.9333333373069763], [0.8583861589431763, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1139 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.6983 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6170 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5832 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4970 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3205 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.3829 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1906 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4739 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0338 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3037 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0207 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0126 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6190 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0082 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0373 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.9076 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4134 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.0788 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0152 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4934 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.0074 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [18, [0.018332205712795258, 1.0], [0.3036509156227112, 0.9333333373069763], [1.2784281969070435, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1177 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6479 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6355 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6279 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6202 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6365 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6206 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6343 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6125 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6189 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5913 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6201 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5975 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6143 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5882 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5929 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6019 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5745 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5958 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5686 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5591 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5810 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5741 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5547 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5694 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5605 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5281 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5170 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4938 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5266 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4955 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4732 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5050 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4616 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4992 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4583 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4918 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4628 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4844 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4390 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4404 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4213 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4688 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3853 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3966 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3835 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3868 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3821 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3675 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3591 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3654 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3455 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3348 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4229 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3269 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4176 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3145 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4142 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3169 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4118 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3031 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4107 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3024 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4066 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2899 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2739 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4012 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2599 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2554 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3944 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2361 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3925 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2428 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2374 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3886 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2234 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3878 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3898 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2115 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3866 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2042 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3974 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1955 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3875 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1982 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3807 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1837 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3814 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1837 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1809 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3932 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1725 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3847 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1704 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3792 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1541 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1573 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1466 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3883 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1475 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3892 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1439 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3915 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1495 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3877 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1344 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3897 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1322 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3997 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1319 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4013 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-06 [88, [0.13715149462223053, 1.0], [0.3792329728603363, 0.8666666746139526], [0.6853798627853394, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1215 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6303 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6157 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6365 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6194 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5951 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6228 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5761 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6068 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5524 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5460 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5251 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5968 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5099 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5877 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5093 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5862 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5096 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5572 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5045 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4831 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5518 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4664 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5535 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4669 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4661 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5459 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4611 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5412 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4538 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5368 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4629 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5407 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4447 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5321 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4318 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4163 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5161 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4227 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5161 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3914 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3999 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3871 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4989 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3761 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4966 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3964 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4927 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3530 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3795 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5454 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3676 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4861 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3414 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3460 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4749 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3112 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3234 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3107 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4557 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3102 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3152 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2857 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4423 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2841 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2836 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2799 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2847 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2700 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4149 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2777 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4286 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2452 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4188 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2614 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2468 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2479 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2377 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4247 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2490 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2356 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3937 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2410 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2291 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3866 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2233 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3842 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2166 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2132 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3964 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3823 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2345 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4255 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4217 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3930 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2084 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3838 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3757 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3693 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1984 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3688 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3737 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1954 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3897 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1989 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3874 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1756 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3605 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1781 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3586 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3592 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1636 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3560 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1708 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3557 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3514 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1675 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3501 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1581 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3587 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1564 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3493 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1545 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3467 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1435 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3524 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3544 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3501 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3457 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1430 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1353 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3469 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1344 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3504 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1341 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3465 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3436 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1314 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3417 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3521 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1243 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1226 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3408 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3369 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3409 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3351 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3342 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3336 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3334 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1180 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3356 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3400 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3423 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3399 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3406 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1059 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1039 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3438 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1082 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3357 - val_sparse_categorical_accuracy: 0.9333\n",
      "1e-06 [139, [0.10495254397392273, 0.9882352948188782], [0.33339378237724304, 0.9333333373069763], [0.8220292925834656, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1253 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.7674 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7525 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7287 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7374 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7411 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7227 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7170 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6998 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6366 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6353 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6369 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6469 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6234 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6243 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6302 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6312 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6101 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6175 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6238 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6148 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6098 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6129 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5973 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6115 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5984 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6008 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5952 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5911 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5906 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5588 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5511 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5753 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5507 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5352 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5461 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5725 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5208 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5735 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5180 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5224 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5127 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5589 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5119 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5553 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5044 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5474 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5018 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5512 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4822 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5409 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4626 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4531 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4477 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4206 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5232 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5337 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4438 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4199 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5164 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4236 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5129 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4097 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5196 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3955 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5223 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4011 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5251 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3829 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5044 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3839 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4994 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3892 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3748 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3620 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3672 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3373 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5057 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3554 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4857 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3435 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4750 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3365 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4681 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3225 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3258 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3183 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4795 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2950 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3122 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4772 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2983 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4907 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2886 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4620 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2897 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2916 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2767 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2894 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4820 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2588 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4672 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2626 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2565 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4539 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2472 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4566 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2443 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2548 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4712 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2505 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4531 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [80, [0.24216358363628387, 1.0], [0.43803882598876953, 0.800000011920929], [0.7191925644874573, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1291 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6414 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6631 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6333 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6412 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6201 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6518 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6195 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6444 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6309 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6316 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6488 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6273 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6139 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6378 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6094 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6294 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6222 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6239 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6256 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6296 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6220 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5991 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6063 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5974 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6011 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6053 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5923 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6044 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5837 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5909 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5828 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5897 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5817 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5737 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5796 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5654 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5773 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5699 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5662 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5604 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5642 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5458 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5460 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5602 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5640 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5407 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5597 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5156 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5522 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5216 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5481 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5174 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5351 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5234 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5318 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5082 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5341 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5098 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5061 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5322 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5028 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5241 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4801 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5177 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4894 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5228 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4630 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5156 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4780 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5136 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4704 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5165 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4559 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4726 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4536 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5097 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4528 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4408 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5115 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4268 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5078 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4406 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4954 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4240 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4964 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4004 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4910 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3910 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4943 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3926 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3865 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4857 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3740 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3804 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3710 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4610 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3569 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3415 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3512 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3456 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4607 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3504 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4612 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3260 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4501 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3319 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3118 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3260 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3107 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2941 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2960 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2878 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4571 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2906 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2739 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2567 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4335 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2533 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2655 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4460 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2577 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4484 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2341 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4311 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4230 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2214 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2181 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2170 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2027 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2185 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2131 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4190 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4185 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4293 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1787 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4121 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1714 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1640 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4073 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4155 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1400 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4455 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1179 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [126, [0.1153496578335762, 0.9764705896377563], [0.4028790295124054, 0.800000011920929], [0.7846891283988953, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1329 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7767 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7374 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6414 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6997 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6792 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6309 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6195 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6182 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6470 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6406 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6178 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6181 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6399 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6125 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6376 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6006 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6172 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5851 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6402 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.5783 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6131 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5859 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5692 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5997 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5641 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5837 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5662 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5506 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5591 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5443 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5457 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5445 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5225 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5153 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5212 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5079 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5170 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4891 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5024 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4834 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5007 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5025 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4983 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4920 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4749 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4697 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4904 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4304 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4461 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4795 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4699 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4333 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4665 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4260 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4661 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4703 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4086 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4618 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3951 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3988 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3886 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3663 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3716 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3671 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3840 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4563 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3481 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3274 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4364 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3343 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4418 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3354 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3074 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3164 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2978 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4357 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2971 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2932 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2882 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2997 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2719 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4321 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2780 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2687 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2610 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2506 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2626 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4443 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2464 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2406 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2277 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2291 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2345 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4418 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2203 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4378 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2155 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [72, [0.21080473065376282, 0.9882352948188782], [0.4149557650089264, 0.800000011920929], [0.7231748700141907, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1367 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6802 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6672 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6402 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6105 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6057 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5687 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6015 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5471 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5868 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5512 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5131 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4889 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5330 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4212 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5126 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4235 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5194 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4139 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4975 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4032 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4944 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3632 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4917 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3457 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4808 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3567 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4778 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3385 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4868 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3007 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3161 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3002 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2789 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4512 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2776 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2489 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2251 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2184 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4311 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2078 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2000 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4148 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1803 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4087 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1793 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4068 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1890 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5073 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1721 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1739 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3918 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3834 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3723 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1310 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3632 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1243 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3832 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1140 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3605 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3568 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1046 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3852 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3975 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1082 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0969 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3386 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1077 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3771 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0939 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3819 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0898 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3595 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0884 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3368 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0900 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0883 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0799 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3388 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0886 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3576 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0813 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3804 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0789 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3439 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0807 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3270 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0771 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3258 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0706 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0709 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3238 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0704 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3238 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0714 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3278 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0655 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0682 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3315 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0643 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0672 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0658 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3207 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0618 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0628 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3225 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0614 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3289 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0572 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3487 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0590 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3445 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0579 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0554 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3203 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0587 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3252 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0564 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3315 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3198 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0510 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3275 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0563 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0510 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0540 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4027 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0534 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0521 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3910 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0496 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0498 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3252 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0468 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0461 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3221 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0458 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3233 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0470 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3287 - val_sparse_categorical_accuracy: 0.9333\n",
      "2e-06 [97, [0.04666449502110481, 1.0], [0.3190551698207855, 0.9333333373069763], [0.9286099076271057, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1405 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6480 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6433 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6530 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6103 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6245 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6015 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6420 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5800 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5639 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.6167 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5706 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5896 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5838 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5424 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5692 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5337 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5880 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5111 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4915 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4505 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4596 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5266 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4233 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5442 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4266 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5226 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4076 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5095 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3870 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5021 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3692 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4971 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3578 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4932 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4900 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3498 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3224 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4841 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3059 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4828 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2875 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4831 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2951 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4855 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2742 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4907 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2725 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2417 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2312 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2278 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2031 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2031 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4660 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1935 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1816 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1656 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1668 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1519 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1592 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1416 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1369 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4251 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1376 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4249 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1273 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1282 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4179 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1191 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4184 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1169 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4168 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1133 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4145 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1065 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4121 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1140 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1050 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4066 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1016 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3989 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0955 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3958 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0977 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3957 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0910 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3953 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0899 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0824 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3959 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0854 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3983 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0825 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3951 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0826 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4030 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0789 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3964 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0745 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0757 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0709 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3954 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0690 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0716 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3934 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0653 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0672 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3935 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0640 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3940 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0635 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0616 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0573 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3969 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0617 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3951 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0583 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3909 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0573 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3891 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0535 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0550 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3896 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0531 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3941 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0516 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0536 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0482 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3866 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0467 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3871 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0471 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0447 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3899 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0463 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3927 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0446 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3955 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0434 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3942 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0418 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3913 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0430 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3879 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0419 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3879 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0398 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3882 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [97, [0.04046683758497238, 1.0], [0.38659295439720154, 0.8666666746139526], [0.8579649925231934, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1443 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6583 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6440 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6381 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6243 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6241 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5785 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5806 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5637 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5459 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5765 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5217 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5549 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5046 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5405 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4823 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5167 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4785 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5054 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4409 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4370 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4922 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4022 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4863 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3889 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4674 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3812 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4629 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3580 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3460 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4601 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3249 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3071 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4443 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3057 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4532 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2867 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4660 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2694 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2703 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2587 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4072 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2288 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4243 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1991 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4236 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1942 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4047 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1888 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3980 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1911 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4296 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1952 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3837 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1845 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3761 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1587 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4138 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1562 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3625 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1726 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3574 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4490 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1560 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3884 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1429 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3555 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1360 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3525 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1316 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4103 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1202 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1207 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3823 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1179 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3791 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1092 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3911 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1123 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1057 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4096 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0954 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4004 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0965 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3923 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [59, [0.11908663809299469, 1.0], [0.35245296359062195, 0.9333333373069763], [0.7368711829185486, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1481 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6420 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6477 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6362 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6145 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6139 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5912 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6268 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6033 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6136 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5842 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6134 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5685 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6152 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5606 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.6053 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5672 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5422 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5982 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5405 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5977 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5221 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5107 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5762 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5157 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4889 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5813 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4765 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4752 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4584 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5776 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4390 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5572 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4459 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4118 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5628 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3976 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5616 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3961 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5350 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3800 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5193 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3648 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5205 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3595 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3434 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5225 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3313 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5048 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3254 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5162 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3137 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3153 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4968 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2928 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4975 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2888 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2774 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4584 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2785 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4524 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2640 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2566 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2458 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2443 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2296 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2318 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4649 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2242 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4931 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2157 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2020 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2090 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4386 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1906 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1888 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1950 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4183 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1756 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1669 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1663 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1611 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1641 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4201 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1661 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4456 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1541 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4296 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1515 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4144 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1440 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1433 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4041 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1373 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4005 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1352 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4046 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4101 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1272 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4105 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1245 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4051 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1199 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1166 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3946 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3910 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1189 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3910 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1155 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1163 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3809 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1103 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3779 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1074 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3813 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1077 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3761 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1025 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3768 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0956 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3795 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1024 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3811 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0942 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3810 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0981 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3772 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0987 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0946 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0859 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0871 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3717 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0900 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3711 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0836 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0869 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3745 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0917 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3681 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0774 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3675 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0795 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3689 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0769 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3709 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0763 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0757 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3625 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0743 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3608 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0725 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3611 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0706 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3705 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0724 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3681 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.0714 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3647 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0701 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0701 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3628 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0665 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3660 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0660 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3734 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0636 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3665 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0623 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3693 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [106, [0.06974273175001144, 1.0], [0.360821396112442, 0.9333333373069763], [0.7305521368980408, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1519 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.7957 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7292 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7473 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6384 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6249 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6054 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6120 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5992 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6179 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5967 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5879 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5662 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5698 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5656 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5676 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5481 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5378 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5410 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5135 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4956 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5077 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4871 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5082 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5031 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4435 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4858 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4336 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4004 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4931 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3849 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4704 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3730 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3694 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3154 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4679 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2911 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4506 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2712 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2609 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4494 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2536 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2456 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4432 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2283 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2137 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2128 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2063 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1893 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4421 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1888 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4271 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4200 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1793 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1701 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4169 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1623 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4032 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1580 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4230 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1593 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1520 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4123 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1394 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4183 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1349 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1342 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4081 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1296 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1266 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1330 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4169 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1228 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4057 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [55, [0.13323214650154114, 1.0], [0.4031858444213867, 0.8666666746139526], [0.7399613857269287, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1557 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6425 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6399 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6076 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5717 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5708 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5240 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5430 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5162 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5207 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4837 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4294 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4940 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3965 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3767 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3307 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4933 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3038 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2769 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2478 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2125 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4501 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1824 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4536 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4460 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1453 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1346 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1258 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1114 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4197 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0982 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0952 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4405 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0890 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0813 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4315 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0765 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4479 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0713 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0646 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0631 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4450 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0610 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0580 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4405 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [34, [0.09139303117990494, 1.0], [0.4196856915950775, 0.800000011920929], [0.7419593930244446, 0.699999988079071]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1595 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7667 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6263 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6232 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5641 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5381 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5146 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5287 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5068 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5185 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4565 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4906 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4033 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4634 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3886 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2957 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2814 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3992 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2556 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2116 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1890 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1718 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1591 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1623 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4484 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1394 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1288 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4562 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1155 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1066 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [25, [0.21718451380729675, 1.0], [0.3991727828979492, 0.8666666746139526], [0.679732084274292, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1633 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 10s/step - loss: 0.7014 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6206 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6171 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6057 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6057 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6084 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5997 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5576 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5160 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5250 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4711 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4580 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5117 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4301 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3496 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4786 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3211 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2822 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2539 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2301 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4977 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1758 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1608 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4907 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1485 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4872 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1489 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1204 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5093 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3804 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1277 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5047 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3947 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1135 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3959 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0967 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5859 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5268 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0835 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3878 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0815 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0736 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4726 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0750 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5112 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0710 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4803 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [33, [0.10020306706428528, 1.0], [0.38043874502182007, 0.800000011920929], [0.7873111963272095, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1671 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.7356 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6252 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6095 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5896 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5413 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5635 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5171 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5435 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4801 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4560 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4061 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3730 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5230 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3271 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2900 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5230 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2498 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4777 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2217 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2065 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1791 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4771 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1706 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1628 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5246 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1435 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4920 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1353 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5261 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1276 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5209 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1243 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1061 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4944 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1041 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0987 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4983 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0851 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4922 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0807 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4756 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0778 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4957 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0774 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4916 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0720 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4872 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0688 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4842 - val_sparse_categorical_accuracy: 0.8667\n",
      "5e-06 [36, [0.10070111602544785, 1.0], [0.47081196308135986, 0.8666666746139526], [0.8358393907546997, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1709 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6769 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6516 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6568 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6196 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6167 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5896 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5870 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5364 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5438 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5222 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5643 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5065 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5043 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4351 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4426 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4443 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4066 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4668 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3426 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4795 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3054 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4201 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2885 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4017 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2568 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4245 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2244 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2073 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1813 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1654 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4075 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1433 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1332 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1233 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4219 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1130 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4371 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1045 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4393 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [25, [0.23146913945674896, 0.9647058844566345], [0.4016585648059845, 0.8666666746139526], [0.687821626663208, 0.6600000262260437]]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load BERT model\n",
    "Trainable = True\n",
    "for lr in [1e-4, 2e-4, 5e-4, 1e-5, 2e-5, 5e-5, 1e-6, 2e-6, 5e-6]:\n",
    "    for Ismetles in range (0,5):\n",
    "        TestEredmeny = func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer)\n",
    "        print(lr,  TestEredmeny)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextClassificationDS2A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09d3283c59714ec4bb76e3d474e14cac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928ab0b08c8b4870ac945c5252dbf2ff",
      "placeholder": "",
      "style": "IPY_MODEL_f5f9b726114849978ff0f8ece12bcba9",
      "value": " 228k/228k [00:02&lt;00:00, 76.8kB/s]"
     }
    },
    "0e5baf42d613466c9789d6ed74223515": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24a91bb3dd86425ebe0dd489d07a99e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "382bcdaba94748dfba4de9ac6df3d0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4136d11d23304f44a6fd77bd5078c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a38b3162339e4d49a7c705818d3d9014",
       "IPY_MODEL_b7a8f10c56f84fce8fd9e0325b3c444e"
      ],
      "layout": "IPY_MODEL_858f4eafdb214acd80236294e009f285"
     }
    },
    "49684e0c97d34a558c268306fbbdf3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b033809b6f434f12b338b3ac2119da37",
       "IPY_MODEL_09d3283c59714ec4bb76e3d474e14cac"
      ],
      "layout": "IPY_MODEL_ac8ce475408a49669d263c85042f9530"
     }
    },
    "59e835dce3754a3da47bd3d3106843a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10fdb6c1963442d8dc23bfa989e8183",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b11ffa580c40481890990666b9813e33",
      "value": 442221694
     }
    },
    "858f4eafdb214acd80236294e009f285": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "928ab0b08c8b4870ac945c5252dbf2ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dd6e58d01ff4bcba634f49e52de97b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59e835dce3754a3da47bd3d3106843a8",
       "IPY_MODEL_b1c95a342bd149aa9940cb4b6290f6cc"
      ],
      "layout": "IPY_MODEL_9e1afcdfeaf4406e860f74b6d4fa5634"
     }
    },
    "9e1afcdfeaf4406e860f74b6d4fa5634": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a38b3162339e4d49a7c705818d3d9014": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfb95452bce4570805ef71e5fce0121",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e5baf42d613466c9789d6ed74223515",
      "value": 385
     }
    },
    "a3cddd07fc284418982f9bd6cba0e89f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac8ce475408a49669d263c85042f9530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b033809b6f434f12b338b3ac2119da37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc947b1fa38423b8e579c10f4cad8c3",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6a48091bc4f4680acdd64f2a3fee5cc",
      "value": 227845
     }
    },
    "b11ffa580c40481890990666b9813e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1c95a342bd149aa9940cb4b6290f6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24a91bb3dd86425ebe0dd489d07a99e6",
      "placeholder": "",
      "style": "IPY_MODEL_382bcdaba94748dfba4de9ac6df3d0fc",
      "value": " 442M/442M [00:12&lt;00:00, 34.2MB/s]"
     }
    },
    "b7a8f10c56f84fce8fd9e0325b3c444e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "placeholder": "",
      "style": "IPY_MODEL_a3cddd07fc284418982f9bd6cba0e89f",
      "value": " 385/385 [00:01&lt;00:00, 323B/s]"
     }
    },
    "c10fdb6c1963442d8dc23bfa989e8183": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfb95452bce4570805ef71e5fce0121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1fd9a54bdb847a3a4ac6a9e49f8bea6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc947b1fa38423b8e579c10f4cad8c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f9b726114849978ff0f8ece12bcba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6a48091bc4f4680acdd64f2a3fee5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
