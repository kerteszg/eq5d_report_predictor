{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_DpLDSRFjEUE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random as rand\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, TFBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0YnybPriUKg"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer):\n",
    "        # Load BERT tokenizer\n",
    "        # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Load BERT model\n",
    "        model = TFBertForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", from_pt=True)\n",
    "\n",
    "        # Set up optimizer and loss function\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # transfer learning vs re-training pre-trained BERT model on smaller lr\n",
    "        model.layers[0].trainable = Trainable\n",
    "        print (\"Learning rate: \" + str(lr) + \"    Trainable: \" + str(Trainable))\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])\n",
    "        es = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "        hist = model.fit(train_dataset, epochs=1000, \n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "        \n",
    "        #plt.plot(hist.history[\"loss\"])\n",
    "        #plt.plot(hist.history[\"val_loss\"])\n",
    "        vissza = [len(hist.history[\"loss\"]), model.evaluate(train_dataset, verbose=0), model.evaluate(val_dataset, verbose=0), model.evaluate(test_dataset, verbose=0)]\n",
    "        return vissza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'title_abstract_keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/train_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing measurement properties of EQ-5D-Y-3L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Feasibility of the EQ-5D in the elderly popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing the self-reported health-related qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Testing measurement properties of two EQ-5D yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Use of Antimalarial Agents is Associated with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Comparing measurement properties of EQ-5D-Y-3L...\n",
       "1      0  Feasibility of the EQ-5D in the elderly popula...\n",
       "2      1  Comparing the self-reported health-related qua...\n",
       "3      1  Testing measurement properties of two EQ-5D yo...\n",
       "4      1  Use of Antimalarial Agents is Associated with ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random stratified validation subset split\n",
    "#_diff = 1\n",
    "#while _diff >= .02:\n",
    "#    tts = train_dataset.train_test_split(test_size=.15, shuffle=True)\n",
    "#    _train_ratio, _val_ratio = np.sum(tts[\"train\"][\"label\"]) / len(tts[\"train\"][\"label\"]), np.sum(tts[\"test\"][\"label\"]) / len(tts[\"test\"][\"label\"])\n",
    "#    _diff = abs(_train_ratio - _val_ratio)\n",
    "#    print(_train_ratio, _val_ratio, _diff)\n",
    "#\n",
    "#train_dataset = tts[\"train\"]\n",
    "#val_dataset = tts[\"test\"]\n",
    "\n",
    "\n",
    "#subsets should be fixed for all tests\n",
    "_val_ids = [2, 7, 24, 32, 36, 47, 49, 59, 61, 71, 72, 86, 90, 95, 96]\n",
    "train_dataset = Dataset.from_pandas(df[~df.index.isin(_val_ids)])\n",
    "val_dataset = Dataset.from_pandas(df[df.index.isin(_val_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.611764705882353, 0.6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_dataset[\"label\"]) / len(train_dataset[\"label\"]), np.sum(val_dataset[\"label\"]) / len(val_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/test_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_dataset[\"label\"]) / len(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1ICeIiykZv"
   },
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "4136d11d23304f44a6fd77bd5078c678",
      "858f4eafdb214acd80236294e009f285",
      "a38b3162339e4d49a7c705818d3d9014",
      "b7a8f10c56f84fce8fd9e0325b3c444e",
      "0e5baf42d613466c9789d6ed74223515",
      "cbfb95452bce4570805ef71e5fce0121",
      "a3cddd07fc284418982f9bd6cba0e89f",
      "d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "49684e0c97d34a558c268306fbbdf3f4",
      "ac8ce475408a49669d263c85042f9530",
      "b033809b6f434f12b338b3ac2119da37",
      "09d3283c59714ec4bb76e3d474e14cac",
      "f6a48091bc4f4680acdd64f2a3fee5cc",
      "dcc947b1fa38423b8e579c10f4cad8c3",
      "f5f9b726114849978ff0f8ece12bcba9",
      "928ab0b08c8b4870ac945c5252dbf2ff"
     ]
    },
    "id": "CeS4fX3Jh_tM",
    "outputId": "4a21030d-3d27-4d63-8c06-ba1c10a85dda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def preprocess_function(examples):\n",
    "#    return tokenizer(examples[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encodings = dataset.map(preprocess_function, batched=True)\n",
    "train_encodings = tokenizer(train_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_dataset[\"text\"], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings[0]), len(train_encodings[1]), len(train_encodings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.875"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.sum([t == '[PAD]' for t in train_encodings[e].tokens]) for e in range(0,80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_dataset[\"label\"]\n",
    "val_labels = val_dataset[\"label\"]\n",
    "test_labels = test_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_683 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7055 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6761 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6642 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6368 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5332 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5451 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6125 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5722 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.6087 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2490 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.7769 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2971 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.8862 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1865 - sparse_categorical_accuracy: 0.9412 - val_loss: 3.0517 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3501 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.8013 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0184 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0000 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0055 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7605 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1417 - val_sparse_categorical_accuracy: 0.8000\n",
      "0.0001 [20, [0.09448282420635223, 0.9764705896377563], [0.4272591173648834, 0.8666666746139526], [0.9762547016143799, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_721 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7501 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6664 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6589 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6988 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7067 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6774 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [12, [0.6620779633522034, 0.5647059082984924], [0.6419037580490112, 0.6666666865348816], [0.6779187917709351, 0.5600000023841858]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_759 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7860 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6479 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.5642 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5209 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6132 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4084 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1874 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.6189 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9765 - val_loss: 1.3788 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.2567 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5130 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.8373 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0059 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0556 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0225 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9709 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9514 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 9.0708e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9570 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 8.0902e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9734 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 7.0490e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9938 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 5.7887e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0133 - val_sparse_categorical_accuracy: 0.8667\n",
      "0.0001 [17, [0.10202736407518387, 0.9647058844566345], [0.25674813985824585, 0.9333333373069763], [1.1352403163909912, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_797 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.7103 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6580 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5160 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3480 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.4808 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.8207 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.9533 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1259 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.0324 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2584 - sparse_categorical_accuracy: 0.8824 - val_loss: 1.3841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2288 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.8702 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.9134 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.2414 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0398 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.9715 - val_sparse_categorical_accuracy: 0.8000\n",
      "0.0001 [13, [0.28665968775749207, 0.9411764740943909], [0.38532447814941406, 0.800000011920929], [0.6586809754371643, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_835 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6168 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5819 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5992 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3683 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.3877 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4684 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0232 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0256 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4127 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.3211 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0160 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6377 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0058 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7449 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0032 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8143 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8621 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8984 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9272 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 9.2359e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9492 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 8.9385e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9657 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 7.0863e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9795 - val_sparse_categorical_accuracy: 0.8667\n",
      "0.0001 [21, [0.05013589188456535, 1.0], [0.32112011313438416, 0.800000011920929], [0.8168779015541077, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_873 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 11s/step - loss: 0.7574 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7168 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6721 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7055 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7016 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7022 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6988 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6976 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7073 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7189 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [14, [0.5490702986717224, 0.7411764860153198], [0.5622081756591797, 0.800000011920929], [0.6860582828521729, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_911 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.7587 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.5527 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7746 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7050 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6954 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6701 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6827 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6904 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6354752779006958, 0.6705882549285889], [0.5527480840682983, 0.800000011920929], [0.667168140411377, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_949 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 10s/step - loss: 0.7181 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6260 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6303 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7450 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6962 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.8909 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7392 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6221 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7432 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7235 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7271 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6884 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6792 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.652154803276062, 0.6117647290229797], [0.6259774565696716, 0.6000000238418579], [0.6818398237228394, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_987 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6175 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6280 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.5168 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6302 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7193 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6134 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7054 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6770 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7104 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7091 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6834 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7041 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6853 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [13, [0.5211470127105713, 0.800000011920929], [0.5167525410652161, 0.800000011920929], [0.6975113749504089, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1025 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.8189 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6885 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6525 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6902 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6958 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7145 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6856 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6979 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6799 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7129 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6843 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7038 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6800 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6991 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7169 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [27, [0.6682536005973816, 0.6117647290229797], [0.6730089783668518, 0.6000000238418579], [0.6730111837387085, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1063 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7534 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6947 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7503 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6985 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6966 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7022 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7303 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7051 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7162 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [11, [0.6686492562294006, 0.6117647290229797], [0.6731004118919373, 0.6000000238418579], [0.6730990409851074, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1101 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.9390 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.8601 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7824 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7105 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6890 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7006 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7079 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6881 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6476 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7249 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7411 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6964 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7191 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7188 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [16, [0.6683164238929749, 0.6117647290229797], [0.6730161309242249, 0.6000000238418579], [0.6730159521102905, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1139 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.9625 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7227 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6860 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7071 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7217 - sparse_categorical_accuracy: 0.6118 - val_loss: 1.0705 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7708 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7006 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6956 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6881 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6978 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6993 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7328 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7143 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7247 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6874 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [22, [0.6679527759552002, 0.6117647290229797], [0.6732766628265381, 0.6000000238418579], [0.6732766628265381, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1177 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.9263 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7095 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6988 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6908 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6794 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6866 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6818 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.7250 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6390 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6942 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7018 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [18, [0.6679711937904358, 0.6117647290229797], [0.6731719374656677, 0.6000000238418579], [0.6731719374656677, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1215 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.8202 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.8454 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7628 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7664 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7159 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6862 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6867 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6821 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7007 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6930 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7169 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7433 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7150 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [20, [0.6683840751647949, 0.6117647290229797], [0.6730259656906128, 0.6000000238418579], [0.673025906085968, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1253 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 11s/step - loss: 0.6556 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6295 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6307 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5553 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5205 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4903 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4997 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4551 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3665 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4725 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4225 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0836 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0605 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0453 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0306 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5607 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0225 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0183 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0148 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0129 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [18, [0.13374082744121552, 0.9882352948188782], [0.41863182187080383, 0.8666666746139526], [0.7606121301651001, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1291 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 85s 10s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5862 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5911 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5282 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4618 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5044 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4098 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3324 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2828 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4508 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1919 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1445 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5495 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4559 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5257 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0440 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0273 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6260 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0210 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6520 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0169 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0137 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7475 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-05 [17, [0.2551444470882416, 0.929411768913269], [0.4436773955821991, 0.800000011920929], [0.7078532576560974, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1329 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 10s/step - loss: 0.6861 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6509 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6261 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6135 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5737 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5625 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5097 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4586 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3835 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3275 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5475 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1915 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5272 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0645 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5762 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0425 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0253 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6688 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0202 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7454 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0142 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8102 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0118 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8312 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0099 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7997 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-05 [18, [0.23507623374462128, 0.9176470637321472], [0.48113730549812317, 0.800000011920929], [0.7587321400642395, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1367 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6268 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6258 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5709 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5139 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5410 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4590 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4038 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5100 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2406 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4450 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5151 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1505 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5049 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0896 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0543 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0385 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0228 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0258 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0185 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0132 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7163 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0111 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [18, [0.17367306351661682, 0.9764705896377563], [0.44497793912887573, 0.8666666746139526], [0.7184478640556335, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1405 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 89s 11s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6078 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5580 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5693 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5114 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5249 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4725 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4930 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4375 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3651 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4462 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3063 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4613 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2384 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4247 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4815 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1047 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0887 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0624 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4968 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0503 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5187 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0397 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5262 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0371 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0273 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0223 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5631 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0192 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-05 [20, [0.1215900108218193, 0.9882352948188782], [0.4246729016304016, 0.8666666746139526], [0.8087875247001648, 0.6800000071525574]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1443 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 11s/step - loss: 0.7533 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6282 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6098 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5544 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5249 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4788 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4926 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3606 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4799 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2382 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0974 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0584 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5934 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0344 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0245 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6394 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0152 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0111 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0090 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0075 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0064 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7132 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-05 [16, [0.14756657183170319, 0.9882352948188782], [0.44952595233917236, 0.800000011920929], [0.9367943406105042, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1481 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 11s/step - loss: 0.7772 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6314 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6161 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5818 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5352 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5224 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3504 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2324 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0528 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0260 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0157 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0089 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9553 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0068 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1346 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0053 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1650 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0044 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1362 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0036 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0791 - val_sparse_categorical_accuracy: 0.7333\n",
      "2e-05 [15, [0.2072700560092926, 0.9411764740943909], [0.42280954122543335, 0.800000011920929], [0.7468209266662598, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1519 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5515 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5674 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.4934 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4233 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5158 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2821 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4762 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4090 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5466 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4143 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0549 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0360 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0205 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0158 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0106 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7477 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0083 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8082 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0073 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8463 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0064 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8560 - val_sparse_categorical_accuracy: 0.8000\n",
      "2e-05 [16, [0.10253003984689713, 1.0], [0.40900853276252747, 0.800000011920929], [0.8240640759468079, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1557 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7078 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5946 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6000 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5141 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4787 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4813 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3788 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5052 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2704 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1341 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5841 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.6329 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0201 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5765 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0122 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7719 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0085 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8870 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0064 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9176 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0051 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9105 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0040 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9088 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9244 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9541 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9894 - val_sparse_categorical_accuracy: 0.8000\n",
      "2e-05 [18, [0.030157892033457756, 1.0], [0.444184809923172, 0.7333333492279053], [1.0058319568634033, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1595 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6606 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6388 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6271 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5453 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5025 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4036 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2612 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5280 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5434 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0463 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0185 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6434 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0165 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0089 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7895 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0071 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8569 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0057 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8893 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0049 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8968 - val_sparse_categorical_accuracy: 0.8000\n",
      "2e-05 [15, [0.21619123220443726, 0.9411764740943909], [0.43340128660202026, 0.800000011920929], [0.8004485964775085, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1633 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6986 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6223 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5126 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3937 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5708 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2319 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0363 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.7753 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0121 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8566 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0062 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8673 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.8705 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.0854 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0081 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0719 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [13, [0.33481863141059875, 0.8588235378265381], [0.441360205411911, 0.8666666746139526], [0.7049210071563721, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1671 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7166 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6142 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5472 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5225 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4905 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3488 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5196 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2659 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4938 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2441 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5993 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1790 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5134 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0205 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8845 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0090 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0043 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7746 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0033 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0769 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1826 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-05 [13, [0.3909730911254883, 0.800000011920929], [0.49053674936294556, 0.800000011920929], [0.7602821588516235, 0.5199999809265137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1709 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 10s/step - loss: 0.7420 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.5739 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5675 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7358 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5120 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.4853 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5153 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4801 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0315 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5174 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0129 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5970 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0048 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8485 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9428 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9968 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0318 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 9.4593e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0511 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 8.2252e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0548 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 7.3093e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0545 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [18, [0.03105171211063862, 1.0], [0.4163583517074585, 0.800000011920929], [0.9478884935379028, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1747 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6277 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5409 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5100 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3396 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5032 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0524 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0129 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8965 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0058 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0844 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1398 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1707 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1887 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2039 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 8.6303e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-05 [14, [0.25713762640953064, 0.929411768913269], [0.43079397082328796, 0.8666666746139526], [0.7083832025527954, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1785 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 11s/step - loss: 0.8734 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6319 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5788 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5346 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5015 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4847 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3619 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4285 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5583 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1082 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.7740 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4891 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0114 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8607 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0151 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5473 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1131 - sparse_categorical_accuracy: 0.9765 - val_loss: 1.1158 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1806 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-05 [15, [0.24980278313159943, 0.8941176533699036], [0.3534974455833435, 0.9333333373069763], [0.6452645659446716, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1823 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.8242 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8271 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7763 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7791 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7476 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7327 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6358 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6279 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6132 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5925 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5802 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6348 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5804 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5565 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6054 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5460 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5934 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5115 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5853 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5082 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5777 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4822 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5689 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4575 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5618 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4673 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5537 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4524 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5462 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5383 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4192 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5320 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4099 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5259 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4011 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5214 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3665 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5146 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3637 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.5057 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3486 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4985 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3521 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3157 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4903 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3138 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4831 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4771 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2838 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4726 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2674 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4731 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2751 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4792 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2598 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4670 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2386 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4617 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2223 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4636 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4751 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1991 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4875 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4740 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1768 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1810 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1818 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4726 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1719 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4913 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1649 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4908 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1712 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4693 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-06 [49, [0.18764975666999817, 0.9882352948188782], [0.461665540933609, 0.8666666746139526], [0.7635656595230103, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1861 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6469 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6168 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6636 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6133 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6348 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6081 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6018 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6247 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6319 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6225 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5911 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5959 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6077 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5833 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5827 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5619 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5484 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5433 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5294 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5049 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5207 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5302 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5109 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5016 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4858 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4623 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.4901 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4567 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4866 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4839 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4260 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4824 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3949 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4739 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3956 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4687 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3831 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3791 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3755 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3582 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3449 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3270 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4565 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3221 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3126 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4464 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2964 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2684 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2982 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2724 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4447 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2564 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4567 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2725 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2499 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2250 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4519 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2299 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4661 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2115 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2177 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2091 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [49, [0.24713875353336334, 0.9529411792755127], [0.4425954222679138, 0.800000011920929], [0.7138399481773376, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1899 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7059 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6829 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6509 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6357 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6347 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6213 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6289 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6493 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6246 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5953 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6223 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6159 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5886 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5962 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6064 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5973 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6018 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5594 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5972 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5699 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5741 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5631 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5544 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5615 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5299 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5561 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5064 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5518 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5046 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5453 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4888 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4788 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4786 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5232 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4660 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5162 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4710 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5106 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4458 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5064 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5012 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4126 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4935 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4046 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4830 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3945 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3792 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4732 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3694 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4702 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3499 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3444 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4542 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3423 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4659 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3306 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4637 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3053 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3023 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4405 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3120 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4401 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2790 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2818 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4306 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2757 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2634 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2397 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4198 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2360 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4130 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2308 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4113 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2173 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4174 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2114 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4076 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1995 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1964 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4078 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1883 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3987 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1892 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4026 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1790 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4086 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1707 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4012 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1727 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3976 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1543 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3972 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1508 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3968 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1475 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3959 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1419 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3814 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1437 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1474 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4031 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1426 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3963 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1277 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3798 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1298 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3769 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1244 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3893 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1139 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3988 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1164 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1110 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1134 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3893 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1080 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1085 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4083 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1006 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3869 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0955 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3789 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0991 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3900 - val_sparse_categorical_accuracy: 0.8667\n",
      "1e-06 [82, [0.1082780584692955, 1.0], [0.3769354522228241, 0.8666666746139526], [0.8375467658042908, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1937 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6473 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6477 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6547 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6413 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6449 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6312 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6253 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6313 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6518 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5927 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6213 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6170 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6156 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6082 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6013 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5999 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5976 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5980 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5790 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5815 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5721 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5621 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5500 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5655 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5645 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5601 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5154 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5502 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5238 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5164 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5421 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5163 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4838 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5213 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4810 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5163 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4763 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5106 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4633 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5025 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4513 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4461 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4900 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4845 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4802 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4115 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4715 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4238 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3929 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4620 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3810 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4596 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3640 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4573 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3605 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3368 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3512 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3331 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3388 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3143 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3102 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2991 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2848 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2709 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4357 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2626 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2516 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2480 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2293 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4323 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4378 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4401 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1989 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2115 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4429 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4580 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1624 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [64, [0.18720564246177673, 0.9647058844566345], [0.4272046983242035, 0.800000011920929], [0.7565610408782959, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_1975 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 11s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6823 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6744 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6318 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6309 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6287 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6124 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6121 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5962 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5903 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5834 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5779 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6141 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5621 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5814 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5735 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5686 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5876 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5596 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5814 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5181 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5148 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4914 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4834 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5524 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4831 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4728 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5410 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5339 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4198 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5274 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4260 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5222 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4189 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5151 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4072 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5084 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3841 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5023 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3850 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3601 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4875 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3482 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4832 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3540 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4870 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3294 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3006 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3136 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4752 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2872 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2651 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2674 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4708 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2466 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4714 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2394 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2355 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2366 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4623 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2093 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4662 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2038 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4657 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1889 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4668 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1677 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4667 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1743 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1641 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4667 - val_sparse_categorical_accuracy: 0.8000\n",
      "1e-06 [64, [0.17985160648822784, 0.9882352948188782], [0.4623490571975708, 0.800000011920929], [0.7779493927955627, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2013 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.7770 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.7111 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6477 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6195 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6214 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6039 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5950 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6226 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5816 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6155 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5491 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6074 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5497 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5996 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5247 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5195 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5832 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4927 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4752 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5647 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4267 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3761 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5132 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3548 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5087 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3254 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5144 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3103 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5118 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3015 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5056 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2825 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4979 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4908 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4918 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4902 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2283 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4723 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2036 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4661 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1897 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4780 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1591 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4558 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4686 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1267 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1118 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0918 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0959 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4416 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0752 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0781 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0664 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0684 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0615 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3974 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0607 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3739 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0620 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0548 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3836 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0537 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0488 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4081 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0442 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3959 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0448 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0428 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3657 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0390 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0375 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0361 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3554 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0340 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0361 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3611 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0343 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3726 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0304 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0297 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0289 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3940 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0279 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3534 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0278 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3501 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0266 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3541 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0258 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3420 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0244 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0228 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0223 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3639 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0218 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0216 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4098 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0200 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4092 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0206 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4134 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0203 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0190 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0183 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3797 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [87, [0.01770062744617462, 1.0], [0.34202200174331665, 0.8666666746139526], [1.2274703979492188, 0.6700000166893005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2051 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 87s 11s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6455 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6224 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6589 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6280 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6080 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6351 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5890 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5749 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6188 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5389 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6107 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5385 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5418 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5294 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5823 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5140 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5714 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4722 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5629 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4547 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5465 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4566 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5452 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5495 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4117 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5437 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5389 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3763 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3692 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3448 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5061 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3370 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3117 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4893 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3039 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4862 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2952 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2790 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2376 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2468 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2038 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2056 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4377 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1996 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4159 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1927 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4531 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1731 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4146 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1575 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4074 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1452 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4093 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4183 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4043 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1337 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3711 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4086 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1121 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3642 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1055 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3432 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0972 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3463 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0918 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3688 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0930 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3659 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0817 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0797 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0760 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3525 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0730 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3907 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0653 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3736 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0624 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0622 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0587 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3771 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0594 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3945 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0511 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3588 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0550 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0479 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0434 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3598 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0433 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3624 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0458 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3668 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0425 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4010 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0412 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8000\n",
      "2e-06 [65, [0.04191134124994278, 1.0], [0.34097665548324585, 0.8666666746139526], [0.8640182614326477, 0.6899999976158142]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2089 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 10s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6634 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6330 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6297 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6449 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6088 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6081 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6305 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6015 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6222 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5889 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6109 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5588 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5418 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5255 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4985 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4622 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.6010 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4004 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3902 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.6202 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3508 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3311 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.7389 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3092 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3081 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2475 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.5333\n",
      "2e-06 [21, [0.49094468355178833, 0.8352941274642944], [0.5846802592277527, 0.7333333492279053], [0.6843960285186768, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2127 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 10s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.6594 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6393 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6247 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6201 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6178 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6194 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5869 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5707 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5557 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5534 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5353 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5321 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5237 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5127 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4954 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5005 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4881 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4903 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4655 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.4794 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4659 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4125 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4536 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4049 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3851 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3287 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3121 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4114 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3077 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2740 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2639 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4142 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3968 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3944 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4129 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4094 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4138 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4125 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4370 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [38, [0.18104198575019836, 0.9647058844566345], [0.39375075697898865, 0.8666666746139526], [0.8109493255615234, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2165 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 85s 10s/step - loss: 0.7998 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.7175 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6471 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6295 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6208 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6192 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6250 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6020 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.5970 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5774 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5877 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5661 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5790 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5696 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5128 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5463 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4863 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4465 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5195 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4473 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5231 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4340 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5090 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3860 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4881 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3657 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.4812 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3387 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.4931 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3037 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2827 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4619 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2664 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4519 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2424 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4853 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2268 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4271 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4216 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1874 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1712 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4299 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1609 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1450 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1390 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1283 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4347 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1224 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4479 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1111 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4447 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1104 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1068 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4139 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1093 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0960 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0963 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0947 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4512 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0819 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4136 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0793 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4130 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0832 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0778 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4978 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0715 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0709 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4193 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0698 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3819 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0633 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3900 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5302 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0626 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0680 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5343 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0587 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0546 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0537 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4139 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0475 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0508 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0520 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.8667\n",
      "2e-06 [58, [0.05265168100595474, 1.0], [0.3819299638271332, 0.8666666746139526], [1.043808102607727, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2203 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 86s 10s/step - loss: 0.7044 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6326 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6157 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6055 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6024 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.5674 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5041 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5491 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4625 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4222 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3878 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4725 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3317 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2900 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2463 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1974 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4283 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.3941 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0904 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5472 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0797 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5849 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0577 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5898 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0442 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0423 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0360 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0322 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0276 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7161 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0253 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [28, [0.06775227934122086, 1.0], [0.3941307067871094, 0.800000011920929], [0.9784771800041199, 0.6200000047683716]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2241 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 90s 11s/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6175 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.6022 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6191 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5744 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5924 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.5405 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4970 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5446 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4931 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5200 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5012 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3834 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3406 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3156 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.4225 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2328 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2078 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4180 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4452 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1090 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4214 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0888 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0776 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4560 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0669 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4723 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0564 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4614 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0505 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0433 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4755 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0383 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5302 - val_sparse_categorical_accuracy: 0.8667\n",
      "5e-06 [25, [0.12644436955451965, 0.9882352948188782], [0.4179859161376953, 0.8666666746139526], [0.8337633013725281, 0.6600000262260437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2279 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 85s 10s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6276 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6218 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6303 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6126 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5965 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6025 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5572 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5321 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.4809 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.5400 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4526 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5253 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3934 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5170 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3417 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5187 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2540 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5295 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5680 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5569 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1290 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5592 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.6067 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0871 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5802 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0747 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5726 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0587 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5876 - val_sparse_categorical_accuracy: 0.7333\n",
      "5e-06 [19, [0.31093063950538635, 0.9176470637321472], [0.5170294642448425, 0.7333333492279053], [0.7005026936531067, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2317 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 85s 10s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6380 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5844 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6200 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5475 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5998 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5235 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5840 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4671 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5633 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.5447 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3866 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.3692 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.5181 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.3181 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5085 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2851 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.4978 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.2523 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.5136 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2075 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5136 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5101 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5165 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5240 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0891 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0733 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5371 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0608 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [21, [0.208462193608284, 0.9647058844566345], [0.49779585003852844, 0.800000011920929], [0.7328639030456543, 0.6499999761581421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: True\n",
      "Model: \"tf_bert_for_sequence_classification_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109918464 \n",
      "                                                                 \n",
      " dropout_2355 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,920,002\n",
      "Trainable params: 109,920,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 88s 10s/step - loss: 0.6915 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6256 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.6072 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.6228 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.5726 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5363 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5604 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.5136 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5467 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4595 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.5262 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4421 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.5183 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.4005 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.5178 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3599 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5148 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3106 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2702 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.5234 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.2132 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.5177 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1101 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5209 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0783 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0759 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0582 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5813 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0499 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.5750 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0439 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0315 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.0276 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0261 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0242 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7302 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0202 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7428 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0194 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0163 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.8000\n",
      "5e-06 [30, [0.037285614758729935, 1.0], [0.44136857986450195, 0.800000011920929], [0.9490160942077637, 0.6800000071525574]]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load BERT model\n",
    "Trainable = True\n",
    "for lr in [1e-4, 2e-4, 5e-4, 1e-5, 2e-5, 5e-5, 1e-6, 2e-6, 5e-6]:\n",
    "    for Ismetles in range (0,5):\n",
    "        TestEredmeny = func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer)\n",
    "        print(lr,  TestEredmeny)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextClassificationDS2A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09d3283c59714ec4bb76e3d474e14cac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928ab0b08c8b4870ac945c5252dbf2ff",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f9b726114849978ff0f8ece12bcba9",
      "value": " 228k/228k [00:02&lt;00:00, 76.8kB/s]"
     }
    },
    "0e5baf42d613466c9789d6ed74223515": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24a91bb3dd86425ebe0dd489d07a99e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "382bcdaba94748dfba4de9ac6df3d0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4136d11d23304f44a6fd77bd5078c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a38b3162339e4d49a7c705818d3d9014",
       "IPY_MODEL_b7a8f10c56f84fce8fd9e0325b3c444e"
      ],
      "layout": "IPY_MODEL_858f4eafdb214acd80236294e009f285"
     }
    },
    "49684e0c97d34a558c268306fbbdf3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b033809b6f434f12b338b3ac2119da37",
       "IPY_MODEL_09d3283c59714ec4bb76e3d474e14cac"
      ],
      "layout": "IPY_MODEL_ac8ce475408a49669d263c85042f9530"
     }
    },
    "59e835dce3754a3da47bd3d3106843a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10fdb6c1963442d8dc23bfa989e8183",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b11ffa580c40481890990666b9813e33",
      "value": 442221694
     }
    },
    "858f4eafdb214acd80236294e009f285": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "928ab0b08c8b4870ac945c5252dbf2ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dd6e58d01ff4bcba634f49e52de97b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59e835dce3754a3da47bd3d3106843a8",
       "IPY_MODEL_b1c95a342bd149aa9940cb4b6290f6cc"
      ],
      "layout": "IPY_MODEL_9e1afcdfeaf4406e860f74b6d4fa5634"
     }
    },
    "9e1afcdfeaf4406e860f74b6d4fa5634": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a38b3162339e4d49a7c705818d3d9014": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfb95452bce4570805ef71e5fce0121",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e5baf42d613466c9789d6ed74223515",
      "value": 385
     }
    },
    "a3cddd07fc284418982f9bd6cba0e89f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac8ce475408a49669d263c85042f9530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b033809b6f434f12b338b3ac2119da37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc947b1fa38423b8e579c10f4cad8c3",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6a48091bc4f4680acdd64f2a3fee5cc",
      "value": 227845
     }
    },
    "b11ffa580c40481890990666b9813e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1c95a342bd149aa9940cb4b6290f6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24a91bb3dd86425ebe0dd489d07a99e6",
      "placeholder": "​",
      "style": "IPY_MODEL_382bcdaba94748dfba4de9ac6df3d0fc",
      "value": " 442M/442M [00:12&lt;00:00, 34.2MB/s]"
     }
    },
    "b7a8f10c56f84fce8fd9e0325b3c444e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "placeholder": "​",
      "style": "IPY_MODEL_a3cddd07fc284418982f9bd6cba0e89f",
      "value": " 385/385 [00:01&lt;00:00, 323B/s]"
     }
    },
    "c10fdb6c1963442d8dc23bfa989e8183": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfb95452bce4570805ef71e5fce0121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1fd9a54bdb847a3a4ac6a9e49f8bea6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc947b1fa38423b8e579c10f4cad8c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f9b726114849978ff0f8ece12bcba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6a48091bc4f4680acdd64f2a3fee5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
