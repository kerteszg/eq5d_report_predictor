{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DpLDSRFjEUE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random as rand\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, TFBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0YnybPriUKg"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer):\n",
    "        # Load BERT tokenizer\n",
    "        # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Load BERT model\n",
    "        model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', from_pt=True)\n",
    "\n",
    "        # Set up optimizer and loss function\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # transfer learning vs re-training pre-trained BERT model on smaller lr\n",
    "        model.layers[0].trainable = Trainable\n",
    "        print (\"Learning rate: \" + str(lr) + \"    Trainable: \" + str(Trainable))\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])\n",
    "        es = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "        hist = model.fit(train_dataset, epochs=1000, \n",
    "                validation_data=val_dataset,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "        \n",
    "        #plt.plot(hist.history[\"loss\"])\n",
    "        #plt.plot(hist.history[\"val_loss\"])\n",
    "        vissza = [len(hist.history[\"loss\"]), model.evaluate(train_dataset, verbose=0), model.evaluate(val_dataset, verbose=0), model.evaluate(test_dataset, verbose=0)]\n",
    "        return vissza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'title_abstract_keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/train_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing measurement properties of EQ-5D-Y-3L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Feasibility of the EQ-5D in the elderly popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparing the self-reported health-related qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Testing measurement properties of two EQ-5D yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Use of Antimalarial Agents is Associated with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Comparing measurement properties of EQ-5D-Y-3L...\n",
       "1      0  Feasibility of the EQ-5D in the elderly popula...\n",
       "2      1  Comparing the self-reported health-related qua...\n",
       "3      1  Testing measurement properties of two EQ-5D yo...\n",
       "4      1  Use of Antimalarial Agents is Associated with ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random stratified validation subset split\n",
    "#_diff = 1\n",
    "#while _diff >= .02:\n",
    "#    tts = train_dataset.train_test_split(test_size=.15, shuffle=True)\n",
    "#    _train_ratio, _val_ratio = np.sum(tts[\"train\"][\"label\"]) / len(tts[\"train\"][\"label\"]), np.sum(tts[\"test\"][\"label\"]) / len(tts[\"test\"][\"label\"])\n",
    "#    _diff = abs(_train_ratio - _val_ratio)\n",
    "#    print(_train_ratio, _val_ratio, _diff)\n",
    "#\n",
    "#train_dataset = tts[\"train\"]\n",
    "#val_dataset = tts[\"test\"]\n",
    "\n",
    "\n",
    "#subsets should be fixed for all tests\n",
    "_val_ids = [2, 7, 24, 32, 36, 47, 49, 59, 61, 71, 72, 86, 90, 95, 96]\n",
    "train_dataset = Dataset.from_pandas(df[~df.index.isin(_val_ids)])\n",
    "val_dataset = Dataset.from_pandas(df[df.index.isin(_val_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.611764705882353, 0.6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_dataset[\"label\"]) / len(train_dataset[\"label\"]), np.sum(val_dataset[\"label\"]) / len(val_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Comparing measurement properties of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients [SEP] BACKGROUND: The adult versions EQ-5D-3L and EQ-5D-5L have been extensive compared. This is not the case for the EQ-5D youth versions. The study aim was to compare the measurement properties and responsiveness of EQ-5D-Y-3L and EQ-5D-Y-5L in paediatric patients. METHODS: A sample of patients 8-16\\xa0years old with different diseases and a wide range of disease severity was asked to complete EQ-5D-Y-3L, EQ-5D-Y-5L, PedsQL Generic Core Scale, and selected, appropriate disease-specific instruments, three times. EQ-5D-Y-3L and EQ-5D-Y-5L were compared in terms of: feasibility, (re-)distribution properties, discriminatory power, convergent validity, test-retest reliability, and responsiveness. RESULTS: 286 participating patients suffered from one of the following diseases: major beta-thalassemia, haemophilia, acute lymphoblastic leukaemia, acute illness. Missing responses were comparable between versions of the EQ-5D-Y, suggesting comparable feasibility. The number of patients in the best health state (level profile 11111) was equal in both EQ-5D-Y versions. The projection of EQ-5D-Y-3L scores onto EQ-5D-Y-5L for all dimensions showed that the two additional levels in EQ-5D-Y-5L slightly improved the accuracy of patients in reporting their problems, especially if severe. Convergent validity with PedsQL and disease-specific measures showed that the two EQ-5D-Y versions performed about equally. Test-retest reliability (EQ-5D-Y-3L 0.78 vs EQ-5D-Y-5L 0.84), and sensitivity for detecting health changes, were both better in EQ-5D-Y-5L. CONCLUSIONS: Extending the number of levels did not give clear superiority to EQ-5D-Y-5L over EQ-5D-Y-3L based on the criteria assessed in this study. However, increasing the number of levels benefitted EQ-5D-Y performance in the measurement of moderate to severe problems and especially in longitudinal study designs [SEP] Adolescent; Adult; Child; Humans; Longitudinal Studies; Psychometrics; Quality of Life; Reproducibility of Results; Surveys and Questionnaires; EQ-5D-Y-3L paediatric patients; EQ-5D-Y-5L; Health-related quality of life; Psychometrics',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/test_{}.pkl\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_dataset[\"label\"]) / len(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1ICeIiykZv"
   },
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "4136d11d23304f44a6fd77bd5078c678",
      "858f4eafdb214acd80236294e009f285",
      "a38b3162339e4d49a7c705818d3d9014",
      "b7a8f10c56f84fce8fd9e0325b3c444e",
      "0e5baf42d613466c9789d6ed74223515",
      "cbfb95452bce4570805ef71e5fce0121",
      "a3cddd07fc284418982f9bd6cba0e89f",
      "d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "49684e0c97d34a558c268306fbbdf3f4",
      "ac8ce475408a49669d263c85042f9530",
      "b033809b6f434f12b338b3ac2119da37",
      "09d3283c59714ec4bb76e3d474e14cac",
      "f6a48091bc4f4680acdd64f2a3fee5cc",
      "dcc947b1fa38423b8e579c10f4cad8c3",
      "f5f9b726114849978ff0f8ece12bcba9",
      "928ab0b08c8b4870ac945c5252dbf2ff"
     ]
    },
    "id": "CeS4fX3Jh_tM",
    "outputId": "4a21030d-3d27-4d63-8c06-ba1c10a85dda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def preprocess_function(examples):\n",
    "#    return tokenizer(examples[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encodings = dataset.map(preprocess_function, batched=True)\n",
    "train_encodings = tokenizer(train_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_dataset[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_dataset[\"text\"], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings[0]), len(train_encodings[1]), len(train_encodings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.sum([t == '[PAD]' for t in train_encodings[e].tokens]) for e in range(0,80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_dataset[\"label\"]\n",
    "val_labels = val_dataset[\"label\"]\n",
    "test_labels = test_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 49s 6s/step - loss: 0.6901 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6671 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [11, [0.6581617593765259, 0.6117647290229797], [0.6841015219688416, 0.6000000238418579], [0.6674167513847351, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.9924 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7912 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7836 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7152 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7218 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6369 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6438 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6395 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6512 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [14, [0.6425721049308777, 0.6235294342041016], [0.7049686908721924, 0.6000000238418579], [0.6646384596824646, 0.6299999952316284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6675 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6798 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6398 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6745 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6607 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6412 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6486 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [11, [0.6654389500617981, 0.6117647290229797], [0.6321954131126404, 0.6000000238418579], [0.6826955676078796, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6454 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6631 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6624 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6658 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [11, [0.6627864241600037, 0.6117647290229797], [0.6552903056144714, 0.6000000238418579], [0.6687169075012207, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7015 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6518 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6372 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6290 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0001 [12, [0.6550585627555847, 0.6117647290229797], [0.6953933835029602, 0.6000000238418579], [0.6661490797996521, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6464 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6699 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [12, [0.667578399181366, 0.6117647290229797], [0.6426601409912109, 0.6666666865348816], [0.6780566573143005, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6967 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6607 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6409 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6455 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6928 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6525 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6595895290374756, 0.6117647290229797], [0.6753857731819153, 0.6000000238418579], [0.6701798439025879, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6484 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6306 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6757 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6414 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6519495844841003, 0.6117647290229797], [0.667553722858429, 0.6000000238418579], [0.6703972816467285, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6480 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6556 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6541 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6645763516426086, 0.6117647290229797], [0.6584215760231018, 0.6000000238418579], [0.6780215501785278, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0002    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_379 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6842 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6932 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6477 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6615 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6388 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6578 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6460 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0002 [11, [0.6652642488479614, 0.6117647290229797], [0.6686631441116333, 0.6000000238418579], [0.6730137467384338, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_417 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6973 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6793 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6425 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6352 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [11, [0.6588126420974731, 0.6117647290229797], [0.673507571220398, 0.6000000238418579], [0.6676012277603149, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7303 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7295 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6815 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6625 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6331 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6253 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6299 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6377 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [13, [0.6463955044746399, 0.6235294342041016], [0.6841932535171509, 0.6000000238418579], [0.6668819189071655, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_493 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6433 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7218 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7261 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6458 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7278 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7255 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6406 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7277 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6770 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7250 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6302 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6492 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7173 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7166 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6358 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6327 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6307 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6335 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6324 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6345 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6409 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6319 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6017 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6341 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6030 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6163 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6083 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6037 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6338 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.5859 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6470 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.5959 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6178 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6470 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6197 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6056 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6054 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6240 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6082 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6339 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5860 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5778 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6260 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6537 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6374 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5972 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6485 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6059 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6354 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5963 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5885 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5967 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5937 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6205 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5910 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5867 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6274 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5894 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6237 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6101 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6244 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5959 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6116 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6129 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6032 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5722 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6141 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5794 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5754 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.6033 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5834 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6165 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5923 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6073 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5850 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6023 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6001 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5985 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6100 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5979 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6182 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5694 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5788 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5899 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6052 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5714 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5857 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5882 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.6034 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5736 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5867 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5817 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.5877 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.5771 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5719 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5664 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.8000\n",
      "0.0005 [83, [0.5641902089118958, 0.7411764860153198], [0.5784568190574646, 0.800000011920929], [0.6464208364486694, 0.6399999856948853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_531 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.7263 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6809 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6737 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6382 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6395 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "0.0005 [11, [0.652520477771759, 0.6117647290229797], [0.6791290640830994, 0.6000000238418579], [0.6783355474472046, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0005    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_569 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6954 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6601 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6615 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6447 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6322 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6387 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6667\n",
      "0.0005 [11, [0.6549810767173767, 0.6117647290229797], [0.6600847244262695, 0.6000000238418579], [0.6789636015892029, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_607 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.9637 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9588 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.9500 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9436 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.9230 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9291 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.9119 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9148 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8816 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.9000 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8682 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8862 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8506 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8730 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8497 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8598 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8516 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8473 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8187 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8369 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7994 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8267 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7899 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8168 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8063 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.8070 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7769 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7984 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7663 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7909 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7620 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7833 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7609 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7407 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7299 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7643 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7330 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7587 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7250 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7241 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7481 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7134 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7435 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7049 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7387 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7136 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7342 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6946 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7307 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6962 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7275 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7248 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6971 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7223 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7197 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7173 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7150 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6818 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6890 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6686 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6806 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6707 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6558 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6569 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6492 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6507 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6275 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6362 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6498 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-05 [76, [0.64785236120224, 0.6352941393852234], [0.6985213160514832, 0.6000000238418579], [0.6660433411598206, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_645 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6818 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7051 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6837 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6801 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6761 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6513 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6519 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6779 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-05 [12, [0.6842916011810303, 0.6117647290229797], [0.6483370065689087, 0.6000000238418579], [0.6798296570777893, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_683 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 5s/step - loss: 0.7432 - sparse_categorical_accuracy: 0.3412 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7298 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7017 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7163 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7014 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6989 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6898 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6856 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6844 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6636 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6675 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6658 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-05 [31, [0.6608970761299133, 0.6117647290229797], [0.6710755825042725, 0.6000000238418579], [0.6717053055763245, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_721 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.7108 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6955 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6904 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6931 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6815 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6821 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6759 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6583 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6798 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6639 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-05 [29, [0.6656274199485779, 0.6117647290229797], [0.6665751338005066, 0.6000000238418579], [0.6770401000976562, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_759 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6632 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6593 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6641 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6492 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6552 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6403 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6553 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6576 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6667\n",
      "1e-05 [27, [0.6415325403213501, 0.6235294342041016], [0.655016303062439, 0.6666666865348816], [0.6703420281410217, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_797 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.7368 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6949 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6925 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6852 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6770 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6797 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6736 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6521 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6539 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6475 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-05 [23, [0.6568595767021179, 0.6117647290229797], [0.6728571653366089, 0.6000000238418579], [0.6687665581703186, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_835 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6821 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6526 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6513 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6733 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6539 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6503 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6529 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-05 [14, [0.6642290949821472, 0.6117647290229797], [0.6506097316741943, 0.6666666865348816], [0.6736553907394409, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_873 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6988 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6817 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6743 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6672 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6685 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6698 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6819 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-05 [16, [0.6695181727409363, 0.6117647290229797], [0.6671245694160461, 0.6000000238418579], [0.6724598407745361, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_911 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.7291 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7303 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6794 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6684 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6455 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6393 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6500 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6547 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6556 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-05 [21, [0.6533371806144714, 0.6235294342041016], [0.6958140134811401, 0.6000000238418579], [0.6687894463539124, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_949 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6900 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6953 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6908 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6697 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6802 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6759 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6431 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-05 [18, [0.6602164506912231, 0.6117647290229797], [0.6652930974960327, 0.6000000238418579], [0.6663041114807129, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_987 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.7900 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7159 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7299 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6954 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6593 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6773 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6514 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-05 [15, [0.6588899493217468, 0.6117647290229797], [0.661970317363739, 0.6000000238418579], [0.6698283553123474, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1025 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6828 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-05 [13, [0.6630829572677612, 0.6117647290229797], [0.6874616742134094, 0.6000000238418579], [0.6678220629692078, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1063 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7148 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6482 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6243 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6509 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6438 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-05 [15, [0.6512426137924194, 0.6117647290229797], [0.6889906525611877, 0.6000000238418579], [0.6720603704452515, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1101 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6471 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6686 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6575 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6391 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-05 [13, [0.6558499932289124, 0.6117647290229797], [0.6628788113594055, 0.6000000238418579], [0.6740395426750183, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-05    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1139 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.6810 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6439 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6464 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6362 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6819 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6313 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-05 [14, [0.6470230221748352, 0.6235294342041016], [0.678149938583374, 0.6000000238418579], [0.6679427623748779, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1177 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.7829 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7806 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7790 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7795 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7795 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7785 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7848 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7774 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7751 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7764 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7791 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7753 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7753 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7743 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7863 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7810 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7722 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7869 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7748 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7703 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7702 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7694 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7613 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7684 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7669 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7674 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7649 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7665 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7682 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7656 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7594 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7646 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7559 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7637 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7632 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7627 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7499 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7618 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7579 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7609 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7434 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7600 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7607 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7591 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7564 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7583 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7642 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7575 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7461 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7566 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7573 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7558 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7611 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7425 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7541 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7409 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7533 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7661 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7524 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7474 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7515 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7592 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7391 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7500 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7586 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7492 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7556 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7400 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7476 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7511 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7469 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7625 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7462 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7523 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7454 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7468 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7476 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7439 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7431 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7377 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7424 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7345 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7418 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7385 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7411 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7495 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7404 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7419 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7397 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7428 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7391 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7394 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7384 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7249 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7377 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7208 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7370 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7421 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7363 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7205 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7357 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7323 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7350 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7322 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7343 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7386 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7337 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7247 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7331 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7332 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7334 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7318 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7399 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7312 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7194 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7244 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7300 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7270 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7294 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7307 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7328 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7282 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7197 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7276 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7195 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7265 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7263 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7229 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7186 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7251 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7231 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7226 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7240 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7115 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7091 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7227 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7143 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7148 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7229 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7152 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7205 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7308 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7096 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7194 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7149 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7189 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7061 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7184 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7190 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7179 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7134 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7174 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7133 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7072 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6994 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7161 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7155 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7150 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7145 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7112 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7057 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6990 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7009 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7135 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7069 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7176 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7052 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7044 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7158 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6992 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7108 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6827 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7036 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7132 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6985 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6951 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7033 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6974 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7050 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7083 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6973 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6881 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6957 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7040 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6949 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6929 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6978 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6994 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7050 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6822 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6983 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6790 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7011 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6825 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7039 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7036 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6939 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6639 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6848 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6859 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6939 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6928 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6930 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6777 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6772 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6936 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6743 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6833 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6774 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6898 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6981 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6901 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6839 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6808 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6827 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6583 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6825 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6855 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6434 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6816 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6744 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6730 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6518 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6499 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6845 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6824 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6799 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6773 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6819 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6818 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6821 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6580 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6639 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6496 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6801 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6797 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6591 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6686 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6666 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6751 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6730 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6673 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6592 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6499 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6452 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6496 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6593 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6788 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6544 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6745 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6560 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6500 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6530 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6591 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6411 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 302/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 303/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6513 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 304/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 305/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 306/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 307/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6425 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 308/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6456 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 309/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 310/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6838 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 311/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 312/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7010 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 313/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 314/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 315/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 316/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 317/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 318/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 319/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 320/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6473 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 321/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6474 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 322/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 323/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 324/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 325/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 326/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 327/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 328/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 329/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 330/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 331/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6351 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 332/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6407 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 333/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6488 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 334/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 335/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6463 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 336/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6423 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 337/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 338/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6461 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 339/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 340/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6333 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 341/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6454 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 342/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6576 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 343/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 344/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6318 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 345/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 346/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 347/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 348/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 349/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 350/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6548 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 351/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 352/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 353/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6513 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 354/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6512 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 355/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6456 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 356/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 357/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 358/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6591 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 359/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 360/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6580 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 361/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-06 [361, [0.6457967758178711, 0.6235294342041016], [0.6777259707450867, 0.6000000238418579], [0.6696510314941406, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1215 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7027 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7239 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6978 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7234 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7030 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7230 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6817 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6933 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7217 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7213 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6978 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7077 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7204 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7197 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6963 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7190 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7187 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6989 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7184 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6879 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7180 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6901 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7173 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6972 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6958 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7165 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6960 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7161 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7035 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6945 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7155 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6949 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7000 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7149 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7145 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7137 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6824 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6860 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6817 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6853 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6582 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6773 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6794 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6817 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6841 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6700 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6690 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6817 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6634 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6737 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6750 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6699 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6642 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6533 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6777 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6812 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6473 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6457 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6783 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6771 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6801 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6812 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6750 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6981 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6615 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6695 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6504 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6516 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6541 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6558 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6607 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6516 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6505 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6504 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6531 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6500 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6606 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6401 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6526 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6524 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6512 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6467 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6373 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6519 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6435 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6594 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6690 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6493 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6611 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6493 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6353 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6578 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-06 [246, [0.6528691649436951, 0.6117647290229797], [0.6952237486839294, 0.6000000238418579], [0.6718183159828186, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1253 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6631 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-06 [12, [0.660332202911377, 0.6117647290229797], [0.6958276033401489, 0.6000000238418579], [0.6659777164459229, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1291 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6999 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7004 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7101 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6965 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6958 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6937 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6892 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6991 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6900 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6818 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7038 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6810 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7078 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6787 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6700 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6824 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6891 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6771 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6797 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6767 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6768 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6764 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6832 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6900 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6662 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6748 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6799 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6807 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6879 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6842 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6854 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6783 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6819 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6780 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6852 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6661 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6629 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6716 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6532 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6843 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6886 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6698 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6783 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6599 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6710 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6678 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6843 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6794 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6701 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6609 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6828 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6628 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6646 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6705 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6575 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6450 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6847 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6809 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6801 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6602 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6506 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6698 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6666 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6591 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6661 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6737 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6632 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6703 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6590 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-06 [195, [0.6608614921569824, 0.6117647290229797], [0.6703248620033264, 0.6000000238418579], [0.6707995533943176, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1329 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.7999 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7441 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8119 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8401 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7422 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8015 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7413 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8268 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7404 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8210 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7394 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8331 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7385 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7955 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7376 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8077 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7367 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8088 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7360 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7946 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7352 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8178 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7344 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7954 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8121 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7327 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7747 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7979 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7310 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8005 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7302 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7784 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7912 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7285 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8026 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7277 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8130 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8058 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7261 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7848 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7253 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7958 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7244 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7989 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7886 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7230 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7948 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7222 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8063 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7215 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7799 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7208 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7657 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7201 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7618 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7195 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7810 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7187 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7847 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7179 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7746 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7172 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7856 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7165 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7877 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7672 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7151 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7728 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7143 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7796 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7823 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7606 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7700 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7796 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7719 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7626 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7709 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7577 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7684 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7714 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7716 - sparse_categorical_accuracy: 0.3412 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7844 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7548 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7762 - sparse_categorical_accuracy: 0.3412 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7726 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7690 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7603 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7578 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7642 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7681 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7497 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7526 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7476 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7555 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7563 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7310 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7385 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7296 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7329 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7532 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7463 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7529 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7724 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7498 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7523 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7365 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6928 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7536 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7308 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7644 - sparse_categorical_accuracy: 0.3059 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7263 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7282 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7461 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7275 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7359 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7402 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7563 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7548 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7248 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7374 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7477 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7596 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7383 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7249 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7479 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7233 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7278 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7137 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7124 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7425 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7267 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6817 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7345 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6813 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7304 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7268 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7211 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6802 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7097 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7171 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7104 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7421 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7165 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7132 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7423 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7246 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7216 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7363 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7219 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7227 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7313 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7177 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7389 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7116 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7318 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7008 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7129 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7082 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7061 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7050 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7265 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7087 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7191 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7128 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7121 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7059 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7167 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6711 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7260 - sparse_categorical_accuracy: 0.2941 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7304 - sparse_categorical_accuracy: 0.3294 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7167 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7002 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7116 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6698 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7368 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7104 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7158 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6692 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7077 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6989 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7133 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6684 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7086 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6680 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6961 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7239 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7099 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7101 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6977 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7138 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6889 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7058 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7052 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7057 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7133 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6980 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7012 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6648 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7116 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6961 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7077 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7156 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6640 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7052 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7086 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6979 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7023 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6634 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6943 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6630 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7036 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7030 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7007 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7084 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7018 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6623 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6808 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7004 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7056 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7003 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7044 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6896 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6880 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6899 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6609 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6973 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7169 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6606 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6876 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6605 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6604 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6997 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6819 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6601 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7000 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6600 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7130 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6599 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7012 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6599 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6598 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7005 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6995 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6596 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6812 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6595 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6983 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7000 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7007 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6591 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7013 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6902 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6589 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6958 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6883 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6980 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6743 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6580 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6973 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6790 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6940 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7083 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6574 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6882 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6867 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6824 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6568 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6848 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6568 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6860 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6761 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7054 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6779 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6904 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6901 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6733 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6745 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7032 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6833 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6909 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6852 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6772 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6560 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6701 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6559 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6986 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6793 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6837 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6767 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6884 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6774 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6779 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6769 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6888 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6819 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.6000\n",
      "1e-06 [301, [0.6748836040496826, 0.6117647290229797], [0.6557425856590271, 0.6000000238418579], [0.6732061505317688, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1367 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6906 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6950 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6816 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6902 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6822 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6825 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6664 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6874 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6824 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6825 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6800 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6902 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6733 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6851 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6976 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6927 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6829 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6712 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6960 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6664 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6641 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6854 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6749 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6809 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6743 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6594 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6841 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6928 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6664 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6737 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6581 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6620 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6956 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6598 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6664 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6495 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6782 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6495 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6772 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6659 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-06 [104, [0.6616606712341309, 0.6117647290229797], [0.6914042234420776, 0.6000000238418579], [0.6711170673370361, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1405 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6842 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6810 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6700 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6874 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6808 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6829 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6755 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6554 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6755 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6833 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6912 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6807 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6816 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6822 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6583 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6860 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6563 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6636 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6652 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6855 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6703 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6804 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6844 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6849 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6767 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6756 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6786 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6692 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6567 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6633 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6759 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6739 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6517 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6680 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6690 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6576 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6838 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6555 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6812 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6866 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6594 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6603 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6609 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6684 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6662 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-06 [120, [0.6636430621147156, 0.6117647290229797], [0.683418333530426, 0.6000000238418579], [0.6744614243507385, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1443 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7389 - sparse_categorical_accuracy: 0.3412 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7163 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7134 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7227 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7145 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7002 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7147 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7166 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7039 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7079 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7049 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7099 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6970 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7080 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7036 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6995 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7067 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6975 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7106 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7011 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7067 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6954 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6995 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7005 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6953 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6996 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6892 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6988 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7108 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6921 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6875 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7043 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7018 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6995 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7035 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6971 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6866 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6820 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6776 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6847 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7012 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7006 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6704 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6781 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6895 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6948 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6805 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6772 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6769 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6844 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6736 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6569 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6764 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6853 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6962 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6707 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6763 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6751 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6663 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6771 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6723 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6687 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6775 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6822 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6650 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6836 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6845 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6724 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6631 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6723 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6552 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6658 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6733 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6823 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6679 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6738 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6891 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-06 [115, [0.6633225679397583, 0.6117647290229797], [0.672053337097168, 0.6000000238418579], [0.6673188209533691, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1481 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 46s 6s/step - loss: 0.6614 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6508 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6806 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6503 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6711 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6493 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6741 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6666 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6684 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6632 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6758 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6486 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6607 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6485 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6481 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6526 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6477 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6637 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6789 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6470 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6686 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6764 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6686 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6467 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6464 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6585 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6690 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6729 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6856 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6450 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6449 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6511 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6449 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6792 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6410 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6800 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6624 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6507 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6446 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6527 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6559 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6542 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6697 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6627 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6796 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6593 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6427 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6636 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6734 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6681 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6440 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6623 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6630 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6724 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6498 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-06 [97, [0.659915566444397, 0.6117647290229797], [0.6438966393470764, 0.6000000238418579], [0.6753254532814026, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 2e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1519 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.7186 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7563 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7154 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7552 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7023 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7538 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7086 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.7525 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6997 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7070 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7500 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6949 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7486 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6931 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7473 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7081 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7459 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6873 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6900 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7437 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7426 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7099 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7416 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7053 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7405 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7394 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6777 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7384 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.7373 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6992 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6955 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.7352 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7343 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6960 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7335 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6770 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7327 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6955 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7317 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6900 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7309 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7002 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7301 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6842 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.7292 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7284 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6950 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7277 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6870 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7262 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7253 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6857 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7238 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7232 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6806 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7226 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6545 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7219 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7212 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6605 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7196 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6720 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7190 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6728 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7186 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6760 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7180 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6438 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.7174 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6744 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6716 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7153 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7148 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6725 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7138 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6620 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6783 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6757 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6672 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6806 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6536 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6674 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6705 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6648 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6551 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6821 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6604 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6613 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6660 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6727 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6594 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6685 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6715 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6588 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6549 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6719 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6542 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6565 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6539 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6351 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6530 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6331 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6699 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6433 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6564 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6472 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6500 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6586 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6408 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6803 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6540 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6435 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6607 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6469 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6666 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6538 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6556 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6544 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6552 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6548 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6343 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6395 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6484 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6492 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6474 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6522 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6988 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6600 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6329 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6583 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6505 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6495 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6596 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6649 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6396 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6541 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6369 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6541 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6464 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6462 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6303 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6332 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6501 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6610 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.6000\n",
      "2e-06 [166, [0.6425826549530029, 0.6352941393852234], [0.6982837319374084, 0.6000000238418579], [0.6689234375953674, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1557 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.8334 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7444 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8454 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8207 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7347 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8047 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.7298 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8197 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7252 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.8086 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.7209 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7793 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7168 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7950 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.8061 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7980 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7847 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7986 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7743 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.6950 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7557 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7882 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7813 - sparse_categorical_accuracy: 0.3294 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7321 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6834 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7467 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6808 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7508 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7140 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7425 - sparse_categorical_accuracy: 0.3765 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7420 - sparse_categorical_accuracy: 0.3529 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7195 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7445 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7286 - sparse_categorical_accuracy: 0.4118 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7331 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7100 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7165 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7310 - sparse_categorical_accuracy: 0.3647 - val_loss: 0.6598 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7160 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7088 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6574 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7181 - sparse_categorical_accuracy: 0.4000 - val_loss: 0.6561 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7078 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7218 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7135 - sparse_categorical_accuracy: 0.4471 - val_loss: 0.6533 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7030 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7080 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7013 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6516 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6970 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6504 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6996 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7081 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6493 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6488 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7011 - sparse_categorical_accuracy: 0.4824 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6479 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6476 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7073 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6810 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7012 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6470 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7026 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6780 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6465 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6464 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.7008 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6834 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6735 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6877 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6772 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6849 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6847 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6625 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6509 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6868 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6689 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6693 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6752 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6886 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-06 [71, [0.6808995604515076, 0.6000000238418579], [0.6458707451820374, 0.6000000238418579], [0.6762946248054504, 0.6100000143051147]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1595 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7213 - sparse_categorical_accuracy: 0.3882 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7078 - sparse_categorical_accuracy: 0.4353 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7032 - sparse_categorical_accuracy: 0.4235 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.7099 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7055 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.2667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6984 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7058 - sparse_categorical_accuracy: 0.4706 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6863 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6791 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6853 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6818 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6667 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6781 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6709 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6807 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6820 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6655 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6540 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6620 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6773 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6792 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6700 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6754 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6626 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6713 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6747 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6428 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6596 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6608 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6552 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6696 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6777 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6570 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6537 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6457 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6653 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6589 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6737 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6521 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6524 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6621 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6497 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6528 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6712 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6618 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6740 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6490 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-06 [56, [0.6554137468338013, 0.6117647290229797], [0.6736657619476318, 0.6000000238418579], [0.6698184013366699, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1633 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 44s 6s/step - loss: 0.7005 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7025 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6940 - sparse_categorical_accuracy: 0.5412 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6824 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6861 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6812 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6832 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6997 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6733 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6760 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.4941 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6654 - sparse_categorical_accuracy: 0.6471 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6762 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6830 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6639 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6715 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6651 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6698 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6682 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6696 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6744 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6694 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6580 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6692 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6689 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6685 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6717 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6679 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6595 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6708 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6568 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6610 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6643 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6520 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6502 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6459 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6553 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6718 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.6409 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6571 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6543 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6670 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6470 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6647 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6680 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-06 [51, [0.658572256565094, 0.6117647290229797], [0.6672758460044861, 0.6000000238418579], [0.6655384302139282, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1671 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.6976 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6986 - sparse_categorical_accuracy: 0.5059 - val_loss: 0.6715 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6858 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6996 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6685 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5529 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6813 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5647 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6826 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6657 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.6641 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6726 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6754 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6799 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6628 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6617 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6848 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6624 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6853 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6748 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6588 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6759 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6747 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6924 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6668 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6810 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6722 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6860 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6871 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6656 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6778 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6746 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6616 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6751 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6761 - sparse_categorical_accuracy: 0.6235 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6615 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.6000\n",
      "5e-06 [40, [0.6660352945327759, 0.6117647290229797], [0.6614872217178345, 0.6000000238418579], [0.6746252179145813, 0.6000000238418579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5e-06    Trainable: False\n",
      "Model: \"tf_bert_for_sequence_classification_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1709 (Dropout)      multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 45s 6s/step - loss: 0.7119 - sparse_categorical_accuracy: 0.4588 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6809 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6968 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6776 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6938 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6973 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6795 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6850 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.6755 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6463 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6765 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6464 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.7030 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6667\n",
      "5e-06 [14, [0.685520350933075, 0.6235294342041016], [0.6453707218170166, 0.6666666865348816], [0.6797481775283813, 0.6100000143051147]]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load BERT model\n",
    "Trainable = False\n",
    "for lr in [1e-4, 2e-4, 5e-4, 1e-5, 2e-5, 5e-5, 1e-6, 2e-6, 5e-6]:\n",
    "    for Ismetles in range (0,5):\n",
    "        TestEredmeny = func_betolt(lr, Trainable, train_dataset, val_dataset, test_dataset, tokenizer)\n",
    "        print(lr,  TestEredmeny)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextClassificationDS2A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09d3283c59714ec4bb76e3d474e14cac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928ab0b08c8b4870ac945c5252dbf2ff",
      "placeholder": "",
      "style": "IPY_MODEL_f5f9b726114849978ff0f8ece12bcba9",
      "value": " 228k/228k [00:02&lt;00:00, 76.8kB/s]"
     }
    },
    "0e5baf42d613466c9789d6ed74223515": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24a91bb3dd86425ebe0dd489d07a99e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "382bcdaba94748dfba4de9ac6df3d0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4136d11d23304f44a6fd77bd5078c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a38b3162339e4d49a7c705818d3d9014",
       "IPY_MODEL_b7a8f10c56f84fce8fd9e0325b3c444e"
      ],
      "layout": "IPY_MODEL_858f4eafdb214acd80236294e009f285"
     }
    },
    "49684e0c97d34a558c268306fbbdf3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b033809b6f434f12b338b3ac2119da37",
       "IPY_MODEL_09d3283c59714ec4bb76e3d474e14cac"
      ],
      "layout": "IPY_MODEL_ac8ce475408a49669d263c85042f9530"
     }
    },
    "59e835dce3754a3da47bd3d3106843a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10fdb6c1963442d8dc23bfa989e8183",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b11ffa580c40481890990666b9813e33",
      "value": 442221694
     }
    },
    "858f4eafdb214acd80236294e009f285": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "928ab0b08c8b4870ac945c5252dbf2ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dd6e58d01ff4bcba634f49e52de97b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59e835dce3754a3da47bd3d3106843a8",
       "IPY_MODEL_b1c95a342bd149aa9940cb4b6290f6cc"
      ],
      "layout": "IPY_MODEL_9e1afcdfeaf4406e860f74b6d4fa5634"
     }
    },
    "9e1afcdfeaf4406e860f74b6d4fa5634": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a38b3162339e4d49a7c705818d3d9014": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfb95452bce4570805ef71e5fce0121",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e5baf42d613466c9789d6ed74223515",
      "value": 385
     }
    },
    "a3cddd07fc284418982f9bd6cba0e89f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac8ce475408a49669d263c85042f9530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b033809b6f434f12b338b3ac2119da37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc947b1fa38423b8e579c10f4cad8c3",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6a48091bc4f4680acdd64f2a3fee5cc",
      "value": 227845
     }
    },
    "b11ffa580c40481890990666b9813e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1c95a342bd149aa9940cb4b6290f6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24a91bb3dd86425ebe0dd489d07a99e6",
      "placeholder": "",
      "style": "IPY_MODEL_382bcdaba94748dfba4de9ac6df3d0fc",
      "value": " 442M/442M [00:12&lt;00:00, 34.2MB/s]"
     }
    },
    "b7a8f10c56f84fce8fd9e0325b3c444e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1fd9a54bdb847a3a4ac6a9e49f8bea6",
      "placeholder": "",
      "style": "IPY_MODEL_a3cddd07fc284418982f9bd6cba0e89f",
      "value": " 385/385 [00:01&lt;00:00, 323B/s]"
     }
    },
    "c10fdb6c1963442d8dc23bfa989e8183": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfb95452bce4570805ef71e5fce0121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1fd9a54bdb847a3a4ac6a9e49f8bea6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc947b1fa38423b8e579c10f4cad8c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f9b726114849978ff0f8ece12bcba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6a48091bc4f4680acdd64f2a3fee5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
